{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2a1f3c",
   "metadata": {},
   "source": [
    "# TuFT-Countdown RL\n",
    "\n",
    "This notebook demonstrates a minimal RL fine-tuning workflow on the **Countdown** dataset using **TuFT**:\n",
    "\n",
    "- Load + preprocess the Countdown dataset\n",
    "- Define a reward function (format check + validity + numeric correctness)\n",
    "- Run a minimal **GRPO-like** RL loop (sampling + importance-sampling loss)\n",
    "- Periodically evaluate and optionally plot metrics + save a final checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5c5b1",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "the experiments below were conducted on a local 2× NVIDIA A100-SXM4-80GB setup (Driver 550.54.15, CUDA 12.9).\n",
    "\n",
    "- TuFT server running (e.g. `http://localhost:xxxx`)\n",
    "- API key available\n",
    "- Dependencies installed: `tinker datasets torch matplotlib`\n",
    "\n",
    "Notes:\n",
    "- If you use a mirrored Hugging Face endpoint, set `HF_ENDPOINT` before loading datasets/models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a8f3d2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:36.801954Z",
     "iopub.status.busy": "2026-01-27T11:21:36.801819Z",
     "iopub.status.idle": "2026-01-27T11:21:39.252774Z",
     "shell.execute_reply": "2026-01-27T11:21:39.252358Z",
     "shell.execute_reply.started": "2026-01-27T11:21:36.801939Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK: tinker = 0.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U tinker datasets torch matplotlib\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tinker\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from tinker import types\n",
    "from tinker.types.tensor_data import TensorData\n",
    "\n",
    "\n",
    "print(\"Imports OK: tinker =\", getattr(tinker, \"__version__\", \"unknown\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2f0ef",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfbf7d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:39.253853Z",
     "iopub.status.busy": "2026-01-27T11:21:39.253552Z",
     "iopub.status.idle": "2026-01-27T11:21:39.258435Z",
     "shell.execute_reply": "2026-01-27T11:21:39.258084Z",
     "shell.execute_reply.started": "2026-01-27T11:21:39.253838Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG ===\n",
      "Server: http://localhost:8080\n",
      "Dataset: Jiayi-Pan/Countdown-Tasks-3to4\n",
      "Base model: Qwen/Qwen3-0.6B\n",
      "LoRA rank: 8\n",
      "Steps: 1000 Batch: 4 Group: 16 LR: 0.0001 MaxTokens: 128\n",
      "Train temp: 0.9 | Eval temp: 0.1\n",
      "Continuous shaping: True\n"
     ]
    }
   ],
   "source": [
    "# TuFT server\n",
    "TINKER_BASE_URL = \"http://localhost:8080\"\n",
    "TINKER_API_KEY = \"tml-test-key\"\n",
    "\n",
    "# Dataset (Countdown)\n",
    "DATASET_NAME = \"Jiayi-Pan/Countdown-Tasks-3to4\"\n",
    "\n",
    "# Model\n",
    "BASE_MODEL = \"Qwen/Qwen3-0.6B\"\n",
    "LORA_RANK = 8\n",
    "\n",
    "# Training\n",
    "NUM_STEPS = 1000\n",
    "BATCH_SIZE = 4\n",
    "GROUP_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_TOKENS = 128\n",
    "\n",
    "# Train sampling\n",
    "TEMPERATURE = 0.9\n",
    "\n",
    "# Dataset split\n",
    "TEST_SIZE = 512\n",
    "SEED = 0\n",
    "\n",
    "# Reward shaping\n",
    "FORMAT_SCORE = 0.1\n",
    "USE_CONTINUOUS_SHAPING = True\n",
    "\n",
    "# Evaluation\n",
    "EVAL_EVERY = 30\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_GROUP_SIZE = 1\n",
    "EVAL_TEMPERATURE = 0.1\n",
    "REWARD_EMA_ALPHA = 0.1\n",
    "\n",
    "\n",
    "print(\"=== CONFIG ===\")\n",
    "print(\"Server:\", TINKER_BASE_URL)\n",
    "print(\"Dataset:\", DATASET_NAME)\n",
    "print(\"Base model:\", BASE_MODEL)\n",
    "print(\"LoRA rank:\", LORA_RANK)\n",
    "print(\n",
    "    \"Steps:\",\n",
    "    NUM_STEPS,\n",
    "    \"Batch:\",\n",
    "    BATCH_SIZE,\n",
    "    \"Group:\",\n",
    "    GROUP_SIZE,\n",
    "    \"LR:\",\n",
    "    LEARNING_RATE,\n",
    "    \"MaxTokens:\",\n",
    "    MAX_TOKENS,\n",
    ")\n",
    "print(\"Train temp:\", TEMPERATURE, \"| Eval temp:\", EVAL_TEMPERATURE)\n",
    "print(\"Continuous shaping:\", USE_CONTINUOUS_SHAPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f4e2a",
   "metadata": {},
   "source": [
    "## 2) Dataset loading + preprocessing\n",
    "\n",
    "We create prompt-style questions.\n",
    "\n",
    "Split policy (deterministic):\n",
    "- Test = first `TEST_SIZE` rows\n",
    "- Train = remaining rows (shuffled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1678c3a2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:39.259048Z",
     "iopub.status.busy": "2026-01-27T11:21:39.258871Z",
     "iopub.status.idle": "2026-01-27T11:21:43.906803Z",
     "shell.execute_reply": "2026-01-27T11:21:43.906405Z",
     "shell.execute_reply.started": "2026-01-27T11:21:39.259022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: Jiayi-Pan/Countdown-Tasks-3to4\n",
      "Train size: 489852\n",
      "Test size:  512\n",
      "\n",
      "Sample keys: ['target', 'nums', 'question']\n",
      "Sample question snippet: Using the numbers 20, 37, 9, 44, reach the target number 52. You may use +, -, *, / and parentheses, and each number can ...\n"
     ]
    }
   ],
   "source": [
    "def load_countdown_splits(\n",
    "    dataset_name: str,\n",
    "    split: str,\n",
    "    test_size: int,\n",
    "    seed: int,\n",
    ") -> tuple[Dataset, Dataset]:\n",
    "    \"\"\"Load Countdown dataset and build prompt-style question strings.\"\"\"\n",
    "\n",
    "    ds = datasets.load_dataset(dataset_name, split=split)\n",
    "    if len(ds) <= test_size:\n",
    "        raise ValueError(f\"Dataset too small: len={len(ds)} <= test_size={test_size}\")\n",
    "\n",
    "    test_ds = ds.select(range(test_size))\n",
    "    train_ds = ds.select(range(test_size, len(ds)))\n",
    "\n",
    "    def preprocess_fn(example, _idx):\n",
    "        target = int(example[\"target\"])\n",
    "        nums = list(example[\"nums\"])\n",
    "        nums_str = \", \".join(map(str, nums))\n",
    "\n",
    "        question = (\n",
    "            f\"Using the numbers {nums_str}, reach the target number {target}. \"\n",
    "            f\"You may use +, -, *, / and parentheses, and each number can only be used once. \"\n",
    "            f\"Put ONLY the final expression inside <answer>...</answer>. \"\n",
    "            f\"Example: <answer>(1+2)/3</answer>.\"\n",
    "        )\n",
    "\n",
    "        return {\"question\": question, \"target\": target, \"nums\": nums}\n",
    "\n",
    "    train_ds = train_ds.map(preprocess_fn, with_indices=True).shuffle(seed=seed)\n",
    "    test_ds = test_ds.map(preprocess_fn, with_indices=True)\n",
    "    return train_ds, test_ds\n",
    "\n",
    "\n",
    "train_ds, test_ds = load_countdown_splits(DATASET_NAME, \"train\", TEST_SIZE, SEED)\n",
    "print(\"Dataset loaded:\", DATASET_NAME)\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Test size: \", len(test_ds))\n",
    "\n",
    "print(\"\\nSample keys:\", list(train_ds[0].keys()))\n",
    "print(\"Sample question snippet:\", train_ds[0][\"question\"][:120], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8a5fb",
   "metadata": {},
   "source": [
    "## 3) Reward utilities\n",
    "\n",
    "Reward pipeline:\n",
    "1. Extract `<answer>...</answer>`\n",
    "2. Validate numbers are used exactly once\n",
    "3. Safely `eval()` arithmetic expressions\n",
    "4. Return a shaped reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c7a1bd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:43.907515Z",
     "iopub.status.busy": "2026-01-27T11:21:43.907277Z",
     "iopub.status.idle": "2026-01-27T11:21:43.914704Z",
     "shell.execute_reply": "2026-01-27T11:21:43.914228Z",
     "shell.execute_reply.started": "2026-01-27T11:21:43.907501Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward sanity:\n",
      "  extracted = (2*3)+7\n",
      "  valid_nums = True\n",
      "  eval = 13\n",
      "  reward_exact = 1.0\n"
     ]
    }
   ],
   "source": [
    "_ANSWER_RE = re.compile(r\"<answer>(.*?)</answer>\", flags=re.DOTALL)\n",
    "_ALLOWED_EVAL_RE = re.compile(r\"^[\\d+\\-*/().\\s]+$\")\n",
    "\n",
    "\n",
    "def extract_solution(text: str) -> str | None:\n",
    "    \"\"\"Extract the last <answer>...</answer> content from a model response.\"\"\"\n",
    "\n",
    "    if \"Assistant:\" in text:\n",
    "        text = text.split(\"Assistant:\", 1)[1]\n",
    "    elif \"<|im_start|>assistant\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\", 1)[1]\n",
    "\n",
    "    matches = list(_ANSWER_RE.finditer(text))\n",
    "    if not matches:\n",
    "        return None\n",
    "    return matches[-1].group(1).strip()\n",
    "\n",
    "\n",
    "def validate_equation(equation_str: str, available_numbers: list[int]) -> bool:\n",
    "    \"\"\"Check if equation uses exactly the provided numbers (multiset match).\"\"\"\n",
    "\n",
    "    try:\n",
    "        numbers_in_eq = [int(n) for n in re.findall(r\"\\d+\", equation_str)]\n",
    "        return sorted(numbers_in_eq) == sorted(available_numbers)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate_equation(equation_str: str) -> float | None:\n",
    "    \"\"\"Safely evaluate arithmetic expression if it matches a restricted character set.\"\"\"\n",
    "\n",
    "    try:\n",
    "        if not _ALLOWED_EVAL_RE.match(equation_str):\n",
    "            return None\n",
    "        return eval(equation_str, {\"__builtins__\": None}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_reward(\n",
    "    response_text: str,\n",
    "    target: int,\n",
    "    nums: list[int],\n",
    "    format_score: float,\n",
    "    use_continuous_shaping: bool,\n",
    ") -> float:\n",
    "    \"\"\"Compute reward for a Countdown response.\n",
    "\n",
    "    - 0.0 if no <answer>\n",
    "    - format_score if invalid numbers or invalid eval\n",
    "    - 1.0 if exact\n",
    "    - otherwise optionally use continuous shaping\n",
    "    \"\"\"\n",
    "\n",
    "    equation = extract_solution(response_text)\n",
    "    if equation is None:\n",
    "        return 0.0\n",
    "\n",
    "    if not validate_equation(equation, nums):\n",
    "        return float(format_score)\n",
    "\n",
    "    result = evaluate_equation(equation)\n",
    "    if result is None:\n",
    "        return float(format_score)\n",
    "\n",
    "    err = abs(result - target)\n",
    "    if err < 1e-5:\n",
    "        return 1.0\n",
    "\n",
    "    if not use_continuous_shaping:\n",
    "        return float(format_score)\n",
    "\n",
    "    shaped = format_score + (1.0 - format_score) * (1.0 / (1.0 + err))\n",
    "    return float(shaped)\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "_txt = \"A: <answer>(2*3)+7</answer>\"\n",
    "_eq = extract_solution(_txt)\n",
    "print(\"Reward sanity:\")\n",
    "print(\"  extracted =\", _eq)\n",
    "print(\"  valid_nums =\", validate_equation(_eq, [2, 3, 7]))\n",
    "print(\"  eval =\", evaluate_equation(_eq))\n",
    "print(\"  reward_exact =\", compute_reward(_txt, 13, [2, 3, 7], FORMAT_SCORE, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e9f72",
   "metadata": {},
   "source": [
    "## 4) Few-shot prompt + dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a57d3bb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:43.915338Z",
     "iopub.status.busy": "2026-01-27T11:21:43.915194Z",
     "iopub.status.idle": "2026-01-27T11:21:46.012868Z",
     "shell.execute_reply": "2026-01-27T11:21:46.012362Z",
     "shell.execute_reply.started": "2026-01-27T11:21:43.915326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot chars: 260 | Stop: ['</answer>']\n",
      "Sample target: 52 | nums: [20, 37, 9, 44]\n",
      "Sample prompt snippet: Q: Using the numbers 2, 3, 7, reach the target number 13. You may use +, -, *, / and parentheses, and each number can only be used once. Put ...\n"
     ]
    }
   ],
   "source": [
    "COUNTDOWN_FEWSHOT = (\n",
    "    \"Q: Using the numbers 2, 3, 7, reach the target number 13. \"\n",
    "    \"You may use +, -, *, / and parentheses, and each number can only be used once. \"\n",
    "    \"Put ONLY the final expression inside <answer>...</answer>. \"\n",
    "    \"Example: <answer>(1+2)/3</answer>.\\n\"\n",
    "    \"A: <answer>(2*3)+7</answer>\\n\\n\"\n",
    ")\n",
    "\n",
    "# Stop when </answer> is generated (we still decode whole sequence returned by backend)\n",
    "STOP_SEQS = [\"</answer>\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Problem:\n",
    "    question: str\n",
    "    target: int\n",
    "    nums: list[int]\n",
    "\n",
    "\n",
    "class CountdownDatasetLoader:\n",
    "    \"\"\"Simple dataset wrapper with sequential batching for train/test.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_name: str, test_size: int, seed: int):\n",
    "        train_ds, test_ds = load_countdown_splits(\n",
    "            dataset_name=dataset_name,\n",
    "            split=\"train\",\n",
    "            test_size=test_size,\n",
    "            seed=seed,\n",
    "        )\n",
    "        self.train = train_ds\n",
    "        self.test = test_ds\n",
    "        self.train_idx = 0\n",
    "        self.test_idx = 0\n",
    "\n",
    "    def get_batch(self, batch_size: int, split: str = \"train\") -> list[Problem]:\n",
    "        ds = self.train if split == \"train\" else self.test\n",
    "        idx = self.train_idx if split == \"train\" else self.test_idx\n",
    "\n",
    "        problems: list[Problem] = []\n",
    "        for _ in range(batch_size):\n",
    "            if idx >= len(ds):\n",
    "                idx = 0\n",
    "            row = ds[idx]\n",
    "            idx += 1\n",
    "            problems.append(\n",
    "                Problem(\n",
    "                    question=f\"Q: {row['question']}\\nA:\",\n",
    "                    target=int(row[\"target\"]),\n",
    "                    nums=list(row[\"nums\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if split == \"train\":\n",
    "            self.train_idx = idx\n",
    "        else:\n",
    "            self.test_idx = idx\n",
    "        return problems\n",
    "\n",
    "\n",
    "dataset = CountdownDatasetLoader(DATASET_NAME, TEST_SIZE, SEED)\n",
    "sample_prob = dataset.get_batch(1, split=\"train\")[0]\n",
    "\n",
    "print(\"Few-shot chars:\", len(COUNTDOWN_FEWSHOT), \"| Stop:\", STOP_SEQS)\n",
    "print(\"Sample target:\", sample_prob.target, \"| nums:\", sample_prob.nums)\n",
    "print(\"Sample prompt snippet:\", (COUNTDOWN_FEWSHOT + sample_prob.question)[:140], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb5bd7",
   "metadata": {},
   "source": [
    "## 5) Connect to TuFT server + create LoRA training client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f9e22a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:46.014153Z",
     "iopub.status.busy": "2026-01-27T11:21:46.013967Z",
     "iopub.status.idle": "2026-01-27T11:21:49.909313Z",
     "shell.execute_reply": "2026-01-27T11:21:49.908767Z",
     "shell.execute_reply.started": "2026-01-27T11:21:46.014138Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServiceClient created: <tinker.ServiceClient object at 0x7f65c6d5c440>\n",
      "Training client created: <tinker.TrainingClient object at 0x7f65c45a52e0>\n",
      "LoRA config: {'base_model': 'Qwen/Qwen3-0.6B', 'rank': 8}\n",
      "Tokenizer type: Qwen2TokenizerFast\n"
     ]
    }
   ],
   "source": [
    "service_client = tinker.ServiceClient(base_url=TINKER_BASE_URL, api_key=TINKER_API_KEY)\n",
    "print(\"ServiceClient created:\", service_client)\n",
    "\n",
    "training_client = service_client.create_lora_training_client(\n",
    "    base_model=BASE_MODEL,\n",
    "    rank=LORA_RANK,\n",
    "    train_mlp=True,\n",
    "    train_attn=True,\n",
    "    train_unembed=True,\n",
    ")\n",
    "print(\"Training client created:\", training_client)\n",
    "print(\"LoRA config:\", {\"base_model\": BASE_MODEL, \"rank\": LORA_RANK})\n",
    "\n",
    "tokenizer = training_client.get_tokenizer()\n",
    "print(\"Tokenizer type:\", type(tokenizer).__name__)\n",
    "\n",
    "\n",
    "def make_prompt_model_input(text: str) -> types.ModelInput:\n",
    "    \"\"\"Build ModelInput from text.\n",
    "\n",
    "    Prefer ModelInput.from_text() if available, otherwise encode with tokenizer.\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(types.ModelInput, \"from_text\"):\n",
    "        return types.ModelInput.from_text(text)\n",
    "\n",
    "    toks = tokenizer.encode(text, add_special_tokens=False)\n",
    "    return types.ModelInput(chunks=[types.EncodedTextChunk(tokens=toks)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d6fc3",
   "metadata": {},
   "source": [
    "## 6) Sampling params + optimizer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44cbbf1b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:49.910188Z",
     "iopub.status.busy": "2026-01-27T11:21:49.909830Z",
     "iopub.status.idle": "2026-01-27T11:21:49.915271Z",
     "shell.execute_reply": "2026-01-27T11:21:49.914866Z",
     "shell.execute_reply.started": "2026-01-27T11:21:49.910172Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params set:\n",
      "  train_temp = 0.9\n",
      "  eval_temp  = 0.1\n",
      "  seed       = 0\n"
     ]
    }
   ],
   "source": [
    "sampling_params_train = types.SamplingParams(\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "    stop=STOP_SEQS,\n",
    ")\n",
    "\n",
    "sampling_params_eval = types.SamplingParams(\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=EVAL_TEMPERATURE,\n",
    "    stop=STOP_SEQS,\n",
    ")\n",
    "\n",
    "adam_params = types.AdamParams(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta1=0.9,\n",
    "    beta2=0.95,\n",
    "    eps=1e-8,\n",
    ")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "print(\"Params set:\")\n",
    "print(\"  train_temp =\", TEMPERATURE)\n",
    "print(\"  eval_temp  =\", EVAL_TEMPERATURE)\n",
    "print(\"  seed       =\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3dfe9",
   "metadata": {},
   "source": [
    "## 7) Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c77f7a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:49.915898Z",
     "iopub.status.busy": "2026-01-27T11:21:49.915754Z",
     "iopub.status.idle": "2026-01-27T11:21:49.920321Z",
     "shell.execute_reply": "2026-01-27T11:21:49.919865Z",
     "shell.execute_reply.started": "2026-01-27T11:21:49.915885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval function ready.\n"
     ]
    }
   ],
   "source": [
    "def do_eval(step: int) -> float:\n",
    "    \"\"\"Evaluate current LoRA checkpoint by sampling on test split and computing mean reward.\"\"\"\n",
    "\n",
    "    eval_path = training_client.save_weights_for_sampler(name=f\"eval_{step:06d}\").result().path\n",
    "    eval_client = service_client.create_sampling_client(model_path=eval_path)\n",
    "\n",
    "    probs = dataset.get_batch(EVAL_BATCH_SIZE, split=\"test\")\n",
    "    rewards = []\n",
    "\n",
    "    for prob in probs:\n",
    "        prompt_text = COUNTDOWN_FEWSHOT + prob.question\n",
    "        prompt = make_prompt_model_input(prompt_text)\n",
    "\n",
    "        res = eval_client.sample(\n",
    "            prompt=prompt,\n",
    "            num_samples=EVAL_GROUP_SIZE,\n",
    "            sampling_params=sampling_params_eval,\n",
    "        ).result()\n",
    "\n",
    "        for seq in res.sequences:\n",
    "            toks = list(seq.tokens)\n",
    "            resp_text = tokenizer.decode(toks, skip_special_tokens=True)\n",
    "            r = compute_reward(\n",
    "                response_text=resp_text,\n",
    "                target=prob.target,\n",
    "                nums=prob.nums,\n",
    "                format_score=FORMAT_SCORE,\n",
    "                use_continuous_shaping=USE_CONTINUOUS_SHAPING,\n",
    "            )\n",
    "            rewards.append(float(r))\n",
    "\n",
    "    return sum(rewards) / max(1, len(rewards))\n",
    "\n",
    "\n",
    "print(\"Eval function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466cd5c",
   "metadata": {},
   "source": [
    "## 8) Train loop (GRPO-like)\n",
    "\n",
    "Per training step:\n",
    "- Sample `GROUP_SIZE` rollouts per problem\n",
    "- Compute centered+normalized advantages within each group\n",
    "- Build importance-sampling datums and run a LoRA update\n",
    "- Periodically evaluate and track EMA reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f68a5f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T11:21:49.921063Z",
     "iopub.status.busy": "2026-01-27T11:21:49.920904Z",
     "iopub.status.idle": "2026-01-27T12:03:21.711854Z",
     "shell.execute_reply": "2026-01-27T12:03:21.711263Z",
     "shell.execute_reply.started": "2026-01-27T11:21:49.921051Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RL training: 1000 steps\n",
      "Batch: 4, Group: 16, LR: 0.0001\n",
      "\n",
      "Step    0: train_mean_reward=0.1376 (Δ +0.0000) eval_mean_reward=0.1787 ema_eval_reward=0.1787 kept_rollouts=64 skipped_problems=0\n",
      "Step    1: train_mean_reward=0.1163 (Δ -0.0213) kept_rollouts=64 skipped_problems=0\n",
      "Step    2: train_mean_reward=0.1668 (Δ +0.0505) kept_rollouts=64 skipped_problems=0\n",
      "Step    3: train_mean_reward=0.2073 (Δ +0.0406) kept_rollouts=64 skipped_problems=0\n",
      "Step    4: train_mean_reward=0.2456 (Δ +0.0383) kept_rollouts=64 skipped_problems=0\n",
      "Step    5: train_mean_reward=0.1971 (Δ -0.0485) kept_rollouts=64 skipped_problems=0\n",
      "Step    6: train_mean_reward=0.1578 (Δ -0.0393) kept_rollouts=64 skipped_problems=0\n",
      "Step    7: train_mean_reward=0.3039 (Δ +0.1460) kept_rollouts=64 skipped_problems=0\n",
      "Step    8: train_mean_reward=0.2719 (Δ -0.0320) kept_rollouts=64 skipped_problems=0\n",
      "Step    9: train_mean_reward=0.3101 (Δ +0.0382) kept_rollouts=64 skipped_problems=0\n",
      "Step   10: train_mean_reward=0.2445 (Δ -0.0656) kept_rollouts=64 skipped_problems=0\n",
      "Step   11: train_mean_reward=0.2620 (Δ +0.0175) kept_rollouts=64 skipped_problems=0\n",
      "Step   12: train_mean_reward=0.3906 (Δ +0.1286) kept_rollouts=64 skipped_problems=0\n",
      "Step   13: train_mean_reward=0.3396 (Δ -0.0510) kept_rollouts=64 skipped_problems=0\n",
      "Step   14: train_mean_reward=0.3440 (Δ +0.0044) kept_rollouts=64 skipped_problems=0\n",
      "Step   15: train_mean_reward=0.2811 (Δ -0.0630) kept_rollouts=64 skipped_problems=0\n",
      "Step   16: train_mean_reward=0.5561 (Δ +0.2750) kept_rollouts=64 skipped_problems=0\n",
      "Step   17: train_mean_reward=0.2498 (Δ -0.3062) kept_rollouts=64 skipped_problems=0\n",
      "Step   18: train_mean_reward=0.2018 (Δ -0.0480) kept_rollouts=48 skipped_problems=1\n",
      "Step   19: train_mean_reward=0.7504 (Δ +0.5486) kept_rollouts=64 skipped_problems=0\n",
      "Step   20: train_mean_reward=0.4623 (Δ -0.2881) kept_rollouts=64 skipped_problems=0\n",
      "Step   21: train_mean_reward=0.1516 (Δ -0.3107) kept_rollouts=48 skipped_problems=1\n",
      "Step   22: train_mean_reward=0.3168 (Δ +0.1652) kept_rollouts=48 skipped_problems=1\n",
      "Step   23: train_mean_reward=0.3608 (Δ +0.0441) kept_rollouts=48 skipped_problems=1\n",
      "Step   24: train_mean_reward=0.4451 (Δ +0.0843) kept_rollouts=32 skipped_problems=2\n",
      "Step   25: train_mean_reward=0.3546 (Δ -0.0905) kept_rollouts=32 skipped_problems=2\n",
      "Step   26: train_mean_reward=0.5440 (Δ +0.1894) kept_rollouts=48 skipped_problems=1\n",
      "Step   27: train_mean_reward=0.7835 (Δ +0.2394) kept_rollouts=48 skipped_problems=1\n",
      "Step   28: train_mean_reward=0.3868 (Δ -0.3967) kept_rollouts=32 skipped_problems=2\n",
      "Step   29: train_mean_reward=0.2666 (Δ -0.1202) kept_rollouts=64 skipped_problems=0\n",
      "Step   30: train_mean_reward=0.2618 (Δ -0.0048) eval_mean_reward=0.3707 ema_eval_reward=0.1979 kept_rollouts=48 skipped_problems=1\n",
      "Step   31: train_mean_reward=0.1658 (Δ -0.0961) kept_rollouts=48 skipped_problems=1\n",
      "Step   32: train_mean_reward=0.1599 (Δ -0.0058) kept_rollouts=64 skipped_problems=0\n",
      "Step   33: train_mean_reward=0.3374 (Δ +0.1774) kept_rollouts=48 skipped_problems=1\n",
      "Step   34: train_mean_reward=0.3327 (Δ -0.0047) kept_rollouts=64 skipped_problems=0\n",
      "Step   35: train_mean_reward=0.6734 (Δ +0.3407) kept_rollouts=64 skipped_problems=0\n",
      "Step   36: train_mean_reward=0.3754 (Δ -0.2980) kept_rollouts=64 skipped_problems=0\n",
      "Step   37: train_mean_reward=0.3396 (Δ -0.0358) kept_rollouts=64 skipped_problems=0\n",
      "Step   38: train_mean_reward=0.4353 (Δ +0.0956) kept_rollouts=48 skipped_problems=1\n",
      "Step   39: train_mean_reward=0.4215 (Δ -0.0138) kept_rollouts=48 skipped_problems=1\n",
      "Step   40: train_mean_reward=0.4616 (Δ +0.0401) kept_rollouts=32 skipped_problems=2\n",
      "Step   41: train_mean_reward=0.2435 (Δ -0.2181) kept_rollouts=32 skipped_problems=2\n",
      "Step   42: train_mean_reward=0.5389 (Δ +0.2954) kept_rollouts=48 skipped_problems=1\n",
      "Step   43: train_mean_reward=0.3113 (Δ -0.2275) kept_rollouts=48 skipped_problems=1\n",
      "Step   44: train_mean_reward=0.5286 (Δ +0.2173) kept_rollouts=48 skipped_problems=1\n",
      "Step   45: train_mean_reward=0.2582 (Δ -0.2704) kept_rollouts=48 skipped_problems=1\n",
      "Step   46: train_mean_reward=0.4151 (Δ +0.1569) kept_rollouts=16 skipped_problems=3\n",
      "Step   47: train_mean_reward=0.1405 (Δ -0.2746) kept_rollouts=16 skipped_problems=3\n",
      "Step   48: train_mean_reward=0.5714 (Δ +0.4309) kept_rollouts=16 skipped_problems=3\n",
      "Step   49: train_mean_reward=0.5434 (Δ -0.0279) kept_rollouts=64 skipped_problems=0\n",
      "Step   50: train_mean_reward=0.5929 (Δ +0.0494) kept_rollouts=16 skipped_problems=3\n",
      "Step   51: train_mean_reward=0.3212 (Δ -0.2717) kept_rollouts=48 skipped_problems=1\n",
      "Step   52: train_mean_reward=0.3084 (Δ -0.0128) kept_rollouts=48 skipped_problems=1\n",
      "Step   53: train_mean_reward=0.2784 (Δ -0.0300) kept_rollouts=48 skipped_problems=1\n",
      "Step   54: train_mean_reward=0.1688 (Δ -0.1096) kept_rollouts=16 skipped_problems=3\n",
      "Step   55: train_mean_reward=0.1321 (Δ -0.0367) kept_rollouts=32 skipped_problems=2\n",
      "Step   56: train_mean_reward=0.4075 (Δ +0.2754) kept_rollouts=48 skipped_problems=1\n",
      "Step   57: train_mean_reward=0.5496 (Δ +0.1422) kept_rollouts=48 skipped_problems=1\n",
      "Step   58: train_mean_reward=0.3791 (Δ -0.1706) kept_rollouts=48 skipped_problems=1\n",
      "Step   59: train_mean_reward=0.9456 (Δ +0.5665) kept_rollouts=16 skipped_problems=3\n",
      "Step   60: train_mean_reward=0.1810 (Δ -0.7646) eval_mean_reward=0.3521 ema_eval_reward=0.2133 kept_rollouts=16 skipped_problems=3\n",
      "Step   61: train_mean_reward=0.5593 (Δ +0.3783) kept_rollouts=48 skipped_problems=1\n",
      "Step   62: train_mean_reward=0.3353 (Δ -0.2239) kept_rollouts=48 skipped_problems=1\n",
      "Step   63: train_mean_reward=0.3784 (Δ +0.0431) kept_rollouts=0 skipped_problems=4\n",
      "Step   64: train_mean_reward=0.5355 (Δ +0.1570) kept_rollouts=48 skipped_problems=1\n",
      "Step   65: train_mean_reward=0.3782 (Δ -0.1573) kept_rollouts=32 skipped_problems=2\n",
      "Step   66: train_mean_reward=0.5072 (Δ +0.1290) kept_rollouts=48 skipped_problems=1\n",
      "Step   67: train_mean_reward=0.1509 (Δ -0.3563) kept_rollouts=32 skipped_problems=2\n",
      "Step   68: train_mean_reward=0.1833 (Δ +0.0324) kept_rollouts=32 skipped_problems=2\n",
      "Step   69: train_mean_reward=0.4200 (Δ +0.2367) kept_rollouts=48 skipped_problems=1\n",
      "Step   70: train_mean_reward=0.5691 (Δ +0.1491) kept_rollouts=32 skipped_problems=2\n",
      "Step   71: train_mean_reward=0.1680 (Δ -0.4011) kept_rollouts=64 skipped_problems=0\n",
      "Step   72: train_mean_reward=0.5731 (Δ +0.4050) kept_rollouts=16 skipped_problems=3\n",
      "Step   73: train_mean_reward=0.3280 (Δ -0.2451) kept_rollouts=48 skipped_problems=1\n",
      "Step   74: train_mean_reward=0.1314 (Δ -0.1965) kept_rollouts=32 skipped_problems=2\n",
      "Step   75: train_mean_reward=0.3943 (Δ +0.2629) kept_rollouts=32 skipped_problems=2\n",
      "Step   76: train_mean_reward=0.3608 (Δ -0.0335) kept_rollouts=48 skipped_problems=1\n",
      "Step   77: train_mean_reward=0.3512 (Δ -0.0096) kept_rollouts=0 skipped_problems=4\n",
      "Step   78: train_mean_reward=0.7836 (Δ +0.4325) kept_rollouts=16 skipped_problems=3\n",
      "Step   79: train_mean_reward=0.3327 (Δ -0.4510) kept_rollouts=32 skipped_problems=2\n",
      "Step   80: train_mean_reward=0.4296 (Δ +0.0969) kept_rollouts=16 skipped_problems=3\n",
      "Step   81: train_mean_reward=0.3958 (Δ -0.0337) kept_rollouts=16 skipped_problems=3\n",
      "Step   82: train_mean_reward=0.5077 (Δ +0.1119) kept_rollouts=48 skipped_problems=1\n",
      "Step   83: train_mean_reward=0.3968 (Δ -0.1110) kept_rollouts=64 skipped_problems=0\n",
      "Step   84: train_mean_reward=0.4468 (Δ +0.0500) kept_rollouts=32 skipped_problems=2\n",
      "Step   85: train_mean_reward=0.3967 (Δ -0.0501) kept_rollouts=48 skipped_problems=1\n",
      "Step   86: train_mean_reward=0.7637 (Δ +0.3670) kept_rollouts=32 skipped_problems=2\n",
      "Step   87: train_mean_reward=0.3515 (Δ -0.4122) kept_rollouts=16 skipped_problems=3\n",
      "Step   88: train_mean_reward=0.5182 (Δ +0.1667) kept_rollouts=32 skipped_problems=2\n",
      "Step   89: train_mean_reward=0.3459 (Δ -0.1723) kept_rollouts=32 skipped_problems=2\n",
      "Step   90: train_mean_reward=0.1411 (Δ -0.2048) eval_mean_reward=0.3637 ema_eval_reward=0.2283 kept_rollouts=48 skipped_problems=1\n",
      "Step   91: train_mean_reward=0.3458 (Δ +0.2047) kept_rollouts=32 skipped_problems=2\n",
      "Step   92: train_mean_reward=0.6128 (Δ +0.2670) kept_rollouts=16 skipped_problems=3\n",
      "Step   93: train_mean_reward=0.7923 (Δ +0.1795) kept_rollouts=0 skipped_problems=4\n",
      "Step   94: train_mean_reward=0.1583 (Δ -0.6340) kept_rollouts=32 skipped_problems=2\n",
      "Step   95: train_mean_reward=0.1785 (Δ +0.0202) kept_rollouts=32 skipped_problems=2\n",
      "Step   96: train_mean_reward=0.2291 (Δ +0.0507) kept_rollouts=48 skipped_problems=1\n",
      "Step   97: train_mean_reward=0.3511 (Δ +0.1219) kept_rollouts=16 skipped_problems=3\n",
      "Step   98: train_mean_reward=0.4487 (Δ +0.0976) kept_rollouts=32 skipped_problems=2\n",
      "Step   99: train_mean_reward=0.4165 (Δ -0.0321) kept_rollouts=32 skipped_problems=2\n",
      "Step  100: train_mean_reward=0.4485 (Δ +0.0319) kept_rollouts=16 skipped_problems=3\n",
      "Step  101: train_mean_reward=0.1920 (Δ -0.2565) kept_rollouts=32 skipped_problems=2\n",
      "Step  102: train_mean_reward=0.2553 (Δ +0.0633) kept_rollouts=32 skipped_problems=2\n",
      "Step  103: train_mean_reward=0.1282 (Δ -0.1271) kept_rollouts=48 skipped_problems=1\n",
      "Step  104: train_mean_reward=0.4518 (Δ +0.3236) kept_rollouts=32 skipped_problems=2\n",
      "Step  105: train_mean_reward=0.2620 (Δ -0.1898) kept_rollouts=48 skipped_problems=1\n",
      "Step  106: train_mean_reward=0.5671 (Δ +0.3052) kept_rollouts=0 skipped_problems=4\n",
      "Step  107: train_mean_reward=0.2571 (Δ -0.3100) kept_rollouts=16 skipped_problems=3\n",
      "Step  108: train_mean_reward=0.3622 (Δ +0.1051) kept_rollouts=32 skipped_problems=2\n",
      "Step  109: train_mean_reward=0.3558 (Δ -0.0065) kept_rollouts=0 skipped_problems=4\n",
      "Step  110: train_mean_reward=0.2344 (Δ -0.1214) kept_rollouts=16 skipped_problems=3\n",
      "Step  111: train_mean_reward=0.5471 (Δ +0.3128) kept_rollouts=16 skipped_problems=3\n",
      "Step  112: train_mean_reward=0.5242 (Δ -0.0229) kept_rollouts=32 skipped_problems=2\n",
      "Step  113: train_mean_reward=0.2049 (Δ -0.3193) kept_rollouts=48 skipped_problems=1\n",
      "Step  114: train_mean_reward=0.1928 (Δ -0.0121) kept_rollouts=16 skipped_problems=3\n",
      "Step  115: train_mean_reward=0.8875 (Δ +0.6947) kept_rollouts=0 skipped_problems=4\n",
      "Step  116: train_mean_reward=0.5669 (Δ -0.3206) kept_rollouts=16 skipped_problems=3\n",
      "Step  117: train_mean_reward=0.4826 (Δ -0.0843) kept_rollouts=32 skipped_problems=2\n",
      "Step  118: train_mean_reward=0.6015 (Δ +0.1188) kept_rollouts=32 skipped_problems=2\n",
      "Step  119: train_mean_reward=0.4046 (Δ -0.1969) kept_rollouts=16 skipped_problems=3\n",
      "Step  120: train_mean_reward=0.3996 (Δ -0.0050) eval_mean_reward=0.4191 ema_eval_reward=0.2474 kept_rollouts=16 skipped_problems=3\n",
      "Step  121: train_mean_reward=0.5278 (Δ +0.1282) kept_rollouts=48 skipped_problems=1\n",
      "Step  122: train_mean_reward=0.3674 (Δ -0.1604) kept_rollouts=48 skipped_problems=1\n",
      "Step  123: train_mean_reward=0.3986 (Δ +0.0312) kept_rollouts=48 skipped_problems=1\n",
      "Step  124: train_mean_reward=0.1443 (Δ -0.2543) kept_rollouts=48 skipped_problems=1\n",
      "Step  125: train_mean_reward=0.3773 (Δ +0.2330) kept_rollouts=16 skipped_problems=3\n",
      "Step  126: train_mean_reward=0.5764 (Δ +0.1991) kept_rollouts=32 skipped_problems=2\n",
      "Step  127: train_mean_reward=0.3801 (Δ -0.1963) kept_rollouts=32 skipped_problems=2\n",
      "Step  128: train_mean_reward=0.3625 (Δ -0.0176) kept_rollouts=0 skipped_problems=4\n",
      "Step  129: train_mean_reward=0.6436 (Δ +0.2811) kept_rollouts=32 skipped_problems=2\n",
      "Step  130: train_mean_reward=0.1832 (Δ -0.4604) kept_rollouts=16 skipped_problems=3\n",
      "Step  131: train_mean_reward=0.8098 (Δ +0.6266) kept_rollouts=32 skipped_problems=2\n",
      "Step  132: train_mean_reward=0.3815 (Δ -0.4283) kept_rollouts=16 skipped_problems=3\n",
      "Step  133: train_mean_reward=0.2715 (Δ -0.1100) kept_rollouts=16 skipped_problems=3\n",
      "Step  134: train_mean_reward=0.2211 (Δ -0.0504) kept_rollouts=48 skipped_problems=1\n",
      "Step  135: train_mean_reward=0.4877 (Δ +0.2667) kept_rollouts=0 skipped_problems=4\n",
      "Step  136: train_mean_reward=0.2954 (Δ -0.1923) kept_rollouts=32 skipped_problems=2\n",
      "Step  137: train_mean_reward=0.3390 (Δ +0.0436) kept_rollouts=32 skipped_problems=2\n",
      "Step  138: train_mean_reward=0.1642 (Δ -0.1748) kept_rollouts=48 skipped_problems=1\n",
      "Step  139: train_mean_reward=0.6854 (Δ +0.5212) kept_rollouts=32 skipped_problems=2\n",
      "Step  140: train_mean_reward=0.8744 (Δ +0.1890) kept_rollouts=16 skipped_problems=3\n",
      "Step  141: train_mean_reward=0.9775 (Δ +0.1031) kept_rollouts=16 skipped_problems=3\n",
      "Step  142: train_mean_reward=0.6996 (Δ -0.2779) kept_rollouts=32 skipped_problems=2\n",
      "Step  143: train_mean_reward=0.4413 (Δ -0.2583) kept_rollouts=32 skipped_problems=2\n",
      "Step  144: train_mean_reward=0.1507 (Δ -0.2906) kept_rollouts=32 skipped_problems=2\n",
      "Step  145: train_mean_reward=0.2473 (Δ +0.0966) kept_rollouts=32 skipped_problems=2\n",
      "Step  146: train_mean_reward=0.2732 (Δ +0.0260) kept_rollouts=32 skipped_problems=2\n",
      "Step  147: train_mean_reward=0.2208 (Δ -0.0524) kept_rollouts=16 skipped_problems=3\n",
      "Step  148: train_mean_reward=0.4269 (Δ +0.2061) kept_rollouts=16 skipped_problems=3\n",
      "Step  149: train_mean_reward=0.3541 (Δ -0.0728) kept_rollouts=16 skipped_problems=3\n",
      "Step  150: train_mean_reward=0.4596 (Δ +0.1055) eval_mean_reward=0.4533 ema_eval_reward=0.2680 kept_rollouts=0 skipped_problems=4\n",
      "Step  151: train_mean_reward=0.4217 (Δ -0.0379) kept_rollouts=0 skipped_problems=4\n",
      "Step  152: train_mean_reward=0.7185 (Δ +0.2968) kept_rollouts=16 skipped_problems=3\n",
      "Step  153: train_mean_reward=0.2096 (Δ -0.5089) kept_rollouts=0 skipped_problems=4\n",
      "Step  154: train_mean_reward=0.1641 (Δ -0.0454) kept_rollouts=16 skipped_problems=3\n",
      "Step  155: train_mean_reward=0.2621 (Δ +0.0980) kept_rollouts=16 skipped_problems=3\n",
      "Step  156: train_mean_reward=0.2868 (Δ +0.0247) kept_rollouts=32 skipped_problems=2\n",
      "Step  157: train_mean_reward=0.5706 (Δ +0.2838) kept_rollouts=16 skipped_problems=3\n",
      "Step  158: train_mean_reward=0.5803 (Δ +0.0097) kept_rollouts=16 skipped_problems=3\n",
      "Step  159: train_mean_reward=0.4406 (Δ -0.1397) kept_rollouts=16 skipped_problems=3\n",
      "Step  160: train_mean_reward=0.3882 (Δ -0.0524) kept_rollouts=32 skipped_problems=2\n",
      "Step  161: train_mean_reward=0.4532 (Δ +0.0650) kept_rollouts=16 skipped_problems=3\n",
      "Step  162: train_mean_reward=0.6273 (Δ +0.1741) kept_rollouts=48 skipped_problems=1\n",
      "Step  163: train_mean_reward=0.5953 (Δ -0.0320) kept_rollouts=16 skipped_problems=3\n",
      "Step  164: train_mean_reward=0.2930 (Δ -0.3023) kept_rollouts=32 skipped_problems=2\n",
      "Step  165: train_mean_reward=0.1766 (Δ -0.1164) kept_rollouts=32 skipped_problems=2\n",
      "Step  166: train_mean_reward=0.2373 (Δ +0.0607) kept_rollouts=64 skipped_problems=0\n",
      "Step  167: train_mean_reward=0.3585 (Δ +0.1212) kept_rollouts=16 skipped_problems=3\n",
      "Step  168: train_mean_reward=0.4176 (Δ +0.0590) kept_rollouts=32 skipped_problems=2\n",
      "Step  169: train_mean_reward=0.3389 (Δ -0.0786) kept_rollouts=48 skipped_problems=1\n",
      "Step  170: train_mean_reward=0.1666 (Δ -0.1723) kept_rollouts=48 skipped_problems=1\n",
      "Step  171: train_mean_reward=0.5690 (Δ +0.4024) kept_rollouts=0 skipped_problems=4\n",
      "Step  172: train_mean_reward=0.2156 (Δ -0.3534) kept_rollouts=64 skipped_problems=0\n",
      "Step  173: train_mean_reward=0.6409 (Δ +0.4254) kept_rollouts=16 skipped_problems=3\n",
      "Step  174: train_mean_reward=0.2258 (Δ -0.4151) kept_rollouts=32 skipped_problems=2\n",
      "Step  175: train_mean_reward=0.3794 (Δ +0.1536) kept_rollouts=32 skipped_problems=2\n",
      "Step  176: train_mean_reward=0.2664 (Δ -0.1130) kept_rollouts=32 skipped_problems=2\n",
      "Step  177: train_mean_reward=0.5392 (Δ +0.2728) kept_rollouts=32 skipped_problems=2\n",
      "Step  178: train_mean_reward=0.5361 (Δ -0.0031) kept_rollouts=16 skipped_problems=3\n",
      "Step  179: train_mean_reward=0.5157 (Δ -0.0203) kept_rollouts=32 skipped_problems=2\n",
      "Step  180: train_mean_reward=0.1452 (Δ -0.3705) eval_mean_reward=0.4460 ema_eval_reward=0.2858 kept_rollouts=32 skipped_problems=2\n",
      "Step  181: train_mean_reward=0.4958 (Δ +0.3506) kept_rollouts=16 skipped_problems=3\n",
      "Step  182: train_mean_reward=0.5482 (Δ +0.0523) kept_rollouts=32 skipped_problems=2\n",
      "Step  183: train_mean_reward=0.4613 (Δ -0.0868) kept_rollouts=48 skipped_problems=1\n",
      "Step  184: train_mean_reward=0.3540 (Δ -0.1073) kept_rollouts=0 skipped_problems=4\n",
      "Step  185: train_mean_reward=0.1378 (Δ -0.2162) kept_rollouts=0 skipped_problems=4\n",
      "Step  186: train_mean_reward=0.3690 (Δ +0.2312) kept_rollouts=16 skipped_problems=3\n",
      "Step  187: train_mean_reward=0.3530 (Δ -0.0160) kept_rollouts=16 skipped_problems=3\n",
      "Step  188: train_mean_reward=0.1516 (Δ -0.2014) kept_rollouts=32 skipped_problems=2\n",
      "Step  189: train_mean_reward=0.2310 (Δ +0.0794) kept_rollouts=32 skipped_problems=2\n",
      "Step  190: train_mean_reward=0.5251 (Δ +0.2941) kept_rollouts=48 skipped_problems=1\n",
      "Step  191: train_mean_reward=0.7707 (Δ +0.2456) kept_rollouts=16 skipped_problems=3\n",
      "Step  192: train_mean_reward=0.1820 (Δ -0.5886) kept_rollouts=32 skipped_problems=2\n",
      "Step  193: train_mean_reward=0.3714 (Δ +0.1894) kept_rollouts=16 skipped_problems=3\n",
      "Step  194: train_mean_reward=0.1790 (Δ -0.1924) kept_rollouts=16 skipped_problems=3\n",
      "Step  195: train_mean_reward=0.5590 (Δ +0.3800) kept_rollouts=0 skipped_problems=4\n",
      "Step  196: train_mean_reward=0.6033 (Δ +0.0443) kept_rollouts=0 skipped_problems=4\n",
      "Step  197: train_mean_reward=0.3895 (Δ -0.2139) kept_rollouts=0 skipped_problems=4\n",
      "Step  198: train_mean_reward=0.1441 (Δ -0.2454) kept_rollouts=48 skipped_problems=1\n",
      "Step  199: train_mean_reward=0.3928 (Δ +0.2487) kept_rollouts=0 skipped_problems=4\n",
      "Step  200: train_mean_reward=0.3757 (Δ -0.0171) kept_rollouts=16 skipped_problems=3\n",
      "Step  201: train_mean_reward=0.6102 (Δ +0.2345) kept_rollouts=32 skipped_problems=2\n",
      "Step  202: train_mean_reward=0.5613 (Δ -0.0489) kept_rollouts=16 skipped_problems=3\n",
      "Step  203: train_mean_reward=0.5863 (Δ +0.0249) kept_rollouts=0 skipped_problems=4\n",
      "Step  204: train_mean_reward=0.6941 (Δ +0.1079) kept_rollouts=32 skipped_problems=2\n",
      "Step  205: train_mean_reward=0.1174 (Δ -0.5767) kept_rollouts=16 skipped_problems=3\n",
      "Step  206: train_mean_reward=0.6008 (Δ +0.4834) kept_rollouts=32 skipped_problems=2\n",
      "Step  207: train_mean_reward=0.7823 (Δ +0.1815) kept_rollouts=0 skipped_problems=4\n",
      "Step  208: train_mean_reward=0.5908 (Δ -0.1914) kept_rollouts=32 skipped_problems=2\n",
      "Step  209: train_mean_reward=0.2127 (Δ -0.3781) kept_rollouts=0 skipped_problems=4\n",
      "Step  210: train_mean_reward=0.5784 (Δ +0.3657) eval_mean_reward=0.3345 ema_eval_reward=0.2907 kept_rollouts=16 skipped_problems=3\n",
      "Step  211: train_mean_reward=0.4608 (Δ -0.1176) kept_rollouts=0 skipped_problems=4\n",
      "Step  212: train_mean_reward=0.1601 (Δ -0.3007) kept_rollouts=0 skipped_problems=4\n",
      "Step  213: train_mean_reward=0.1384 (Δ -0.0217) kept_rollouts=32 skipped_problems=2\n",
      "Step  214: train_mean_reward=0.3764 (Δ +0.2380) kept_rollouts=32 skipped_problems=2\n",
      "Step  215: train_mean_reward=0.8163 (Δ +0.4399) kept_rollouts=16 skipped_problems=3\n",
      "Step  216: train_mean_reward=0.5897 (Δ -0.2265) kept_rollouts=16 skipped_problems=3\n",
      "Step  217: train_mean_reward=0.4335 (Δ -0.1562) kept_rollouts=16 skipped_problems=3\n",
      "Step  218: train_mean_reward=0.4702 (Δ +0.0367) kept_rollouts=32 skipped_problems=2\n",
      "Step  219: train_mean_reward=0.2548 (Δ -0.2154) kept_rollouts=0 skipped_problems=4\n",
      "Step  220: train_mean_reward=0.4332 (Δ +0.1784) kept_rollouts=32 skipped_problems=2\n",
      "Step  221: train_mean_reward=0.1327 (Δ -0.3006) kept_rollouts=16 skipped_problems=3\n",
      "Step  222: train_mean_reward=0.1460 (Δ +0.0134) kept_rollouts=48 skipped_problems=1\n",
      "Step  223: train_mean_reward=0.2455 (Δ +0.0995) kept_rollouts=0 skipped_problems=4\n",
      "Step  224: train_mean_reward=0.3179 (Δ +0.0724) kept_rollouts=32 skipped_problems=2\n",
      "Step  225: train_mean_reward=0.3533 (Δ +0.0354) kept_rollouts=32 skipped_problems=2\n",
      "Step  226: train_mean_reward=0.3551 (Δ +0.0018) kept_rollouts=32 skipped_problems=2\n",
      "Step  227: train_mean_reward=0.2049 (Δ -0.1503) kept_rollouts=32 skipped_problems=2\n",
      "Step  228: train_mean_reward=0.7233 (Δ +0.5185) kept_rollouts=16 skipped_problems=3\n",
      "Step  229: train_mean_reward=0.4667 (Δ -0.2566) kept_rollouts=16 skipped_problems=3\n",
      "Step  230: train_mean_reward=0.1388 (Δ -0.3279) kept_rollouts=16 skipped_problems=3\n",
      "Step  231: train_mean_reward=0.1843 (Δ +0.0455) kept_rollouts=16 skipped_problems=3\n",
      "Step  232: train_mean_reward=0.3679 (Δ +0.1837) kept_rollouts=16 skipped_problems=3\n",
      "Step  233: train_mean_reward=0.4691 (Δ +0.1012) kept_rollouts=32 skipped_problems=2\n",
      "Step  234: train_mean_reward=0.4531 (Δ -0.0160) kept_rollouts=0 skipped_problems=4\n",
      "Step  235: train_mean_reward=0.1736 (Δ -0.2795) kept_rollouts=32 skipped_problems=2\n",
      "Step  236: train_mean_reward=0.5493 (Δ +0.3757) kept_rollouts=16 skipped_problems=3\n",
      "Step  237: train_mean_reward=0.3685 (Δ -0.1808) kept_rollouts=0 skipped_problems=4\n",
      "Step  238: train_mean_reward=0.3578 (Δ -0.0108) kept_rollouts=48 skipped_problems=1\n",
      "Step  239: train_mean_reward=0.3914 (Δ +0.0336) kept_rollouts=32 skipped_problems=2\n",
      "Step  240: train_mean_reward=0.5987 (Δ +0.2073) eval_mean_reward=0.3811 ema_eval_reward=0.2997 kept_rollouts=32 skipped_problems=2\n",
      "Step  241: train_mean_reward=0.3460 (Δ -0.2527) kept_rollouts=0 skipped_problems=4\n",
      "Step  242: train_mean_reward=0.3470 (Δ +0.0009) kept_rollouts=48 skipped_problems=1\n",
      "Step  243: train_mean_reward=0.2310 (Δ -0.1160) kept_rollouts=16 skipped_problems=3\n",
      "Step  244: train_mean_reward=0.3685 (Δ +0.1375) kept_rollouts=32 skipped_problems=2\n",
      "Step  245: train_mean_reward=0.1942 (Δ -0.1743) kept_rollouts=32 skipped_problems=2\n",
      "Step  246: train_mean_reward=0.5653 (Δ +0.3711) kept_rollouts=32 skipped_problems=2\n",
      "Step  247: train_mean_reward=0.1551 (Δ -0.4102) kept_rollouts=48 skipped_problems=1\n",
      "Step  248: train_mean_reward=0.2887 (Δ +0.1336) kept_rollouts=16 skipped_problems=3\n",
      "Step  249: train_mean_reward=0.4131 (Δ +0.1243) kept_rollouts=48 skipped_problems=1\n",
      "Step  250: train_mean_reward=0.1993 (Δ -0.2137) kept_rollouts=32 skipped_problems=2\n",
      "Step  251: train_mean_reward=0.2187 (Δ +0.0194) kept_rollouts=48 skipped_problems=1\n",
      "Step  252: train_mean_reward=0.3322 (Δ +0.1135) kept_rollouts=32 skipped_problems=2\n",
      "Step  253: train_mean_reward=0.5077 (Δ +0.1755) kept_rollouts=64 skipped_problems=0\n",
      "Step  254: train_mean_reward=0.3262 (Δ -0.1816) kept_rollouts=32 skipped_problems=2\n",
      "Step  255: train_mean_reward=0.2351 (Δ -0.0910) kept_rollouts=0 skipped_problems=4\n",
      "Step  256: train_mean_reward=1.0000 (Δ +0.7649) kept_rollouts=0 skipped_problems=4\n",
      "Step  257: train_mean_reward=0.3472 (Δ -0.6528) kept_rollouts=16 skipped_problems=3\n",
      "Step  258: train_mean_reward=0.2753 (Δ -0.0719) kept_rollouts=16 skipped_problems=3\n",
      "Step  259: train_mean_reward=0.1941 (Δ -0.0812) kept_rollouts=16 skipped_problems=3\n",
      "Step  260: train_mean_reward=0.3579 (Δ +0.1638) kept_rollouts=0 skipped_problems=4\n",
      "Step  261: train_mean_reward=0.7678 (Δ +0.4099) kept_rollouts=16 skipped_problems=3\n",
      "Step  262: train_mean_reward=0.5502 (Δ -0.2176) kept_rollouts=16 skipped_problems=3\n",
      "Step  263: train_mean_reward=0.3501 (Δ -0.2001) kept_rollouts=16 skipped_problems=3\n",
      "Step  264: train_mean_reward=0.1608 (Δ -0.1893) kept_rollouts=32 skipped_problems=2\n",
      "Step  265: train_mean_reward=0.2307 (Δ +0.0699) kept_rollouts=0 skipped_problems=4\n",
      "Step  266: train_mean_reward=0.3008 (Δ +0.0701) kept_rollouts=0 skipped_problems=4\n",
      "Step  267: train_mean_reward=0.3470 (Δ +0.0463) kept_rollouts=0 skipped_problems=4\n",
      "Step  268: train_mean_reward=0.3640 (Δ +0.0170) kept_rollouts=0 skipped_problems=4\n",
      "Step  269: train_mean_reward=0.3406 (Δ -0.0234) kept_rollouts=16 skipped_problems=3\n",
      "Step  270: train_mean_reward=0.5703 (Δ +0.2296) eval_mean_reward=0.3365 ema_eval_reward=0.3034 kept_rollouts=16 skipped_problems=3\n",
      "Step  271: train_mean_reward=0.1660 (Δ -0.4042) kept_rollouts=16 skipped_problems=3\n",
      "Step  272: train_mean_reward=0.4395 (Δ +0.2735) kept_rollouts=16 skipped_problems=3\n",
      "Step  273: train_mean_reward=0.7314 (Δ +0.2919) kept_rollouts=16 skipped_problems=3\n",
      "Step  274: train_mean_reward=0.5641 (Δ -0.1672) kept_rollouts=16 skipped_problems=3\n",
      "Step  275: train_mean_reward=0.3891 (Δ -0.1750) kept_rollouts=16 skipped_problems=3\n",
      "Step  276: train_mean_reward=0.3828 (Δ -0.0063) kept_rollouts=16 skipped_problems=3\n",
      "Step  277: train_mean_reward=0.5649 (Δ +0.1821) kept_rollouts=0 skipped_problems=4\n",
      "Step  278: train_mean_reward=0.2446 (Δ -0.3203) kept_rollouts=0 skipped_problems=4\n",
      "Step  279: train_mean_reward=0.4160 (Δ +0.1714) kept_rollouts=32 skipped_problems=2\n",
      "Step  280: train_mean_reward=0.3727 (Δ -0.0433) kept_rollouts=16 skipped_problems=3\n",
      "Step  281: train_mean_reward=0.3457 (Δ -0.0270) kept_rollouts=0 skipped_problems=4\n",
      "Step  282: train_mean_reward=0.1478 (Δ -0.1979) kept_rollouts=0 skipped_problems=4\n",
      "Step  283: train_mean_reward=0.1863 (Δ +0.0386) kept_rollouts=32 skipped_problems=2\n",
      "Step  284: train_mean_reward=0.1313 (Δ -0.0551) kept_rollouts=16 skipped_problems=3\n",
      "Step  285: train_mean_reward=0.6351 (Δ +0.5039) kept_rollouts=16 skipped_problems=3\n",
      "Step  286: train_mean_reward=0.5543 (Δ -0.0808) kept_rollouts=16 skipped_problems=3\n",
      "Step  287: train_mean_reward=0.1340 (Δ -0.4203) kept_rollouts=48 skipped_problems=1\n",
      "Step  288: train_mean_reward=0.1444 (Δ +0.0104) kept_rollouts=0 skipped_problems=4\n",
      "Step  289: train_mean_reward=0.3716 (Δ +0.2271) kept_rollouts=32 skipped_problems=2\n",
      "Step  290: train_mean_reward=0.3514 (Δ -0.0202) kept_rollouts=16 skipped_problems=3\n",
      "Step  291: train_mean_reward=0.3548 (Δ +0.0034) kept_rollouts=16 skipped_problems=3\n",
      "Step  292: train_mean_reward=0.4871 (Δ +0.1323) kept_rollouts=16 skipped_problems=3\n",
      "Step  293: train_mean_reward=0.1636 (Δ -0.3235) kept_rollouts=32 skipped_problems=2\n",
      "Step  294: train_mean_reward=0.1569 (Δ -0.0066) kept_rollouts=0 skipped_problems=4\n",
      "Step  295: train_mean_reward=0.3635 (Δ +0.2066) kept_rollouts=0 skipped_problems=4\n",
      "Step  296: train_mean_reward=0.3557 (Δ -0.0078) kept_rollouts=48 skipped_problems=1\n",
      "Step  297: train_mean_reward=0.4562 (Δ +0.1005) kept_rollouts=48 skipped_problems=1\n",
      "Step  298: train_mean_reward=0.4469 (Δ -0.0092) kept_rollouts=32 skipped_problems=2\n",
      "Step  299: train_mean_reward=0.3461 (Δ -0.1008) kept_rollouts=32 skipped_problems=2\n",
      "Step  300: train_mean_reward=0.7782 (Δ +0.4321) eval_mean_reward=0.3553 ema_eval_reward=0.3086 kept_rollouts=0 skipped_problems=4\n",
      "Step  301: train_mean_reward=0.7823 (Δ +0.0041) kept_rollouts=32 skipped_problems=2\n",
      "Step  302: train_mean_reward=0.1680 (Δ -0.6143) kept_rollouts=32 skipped_problems=2\n",
      "Step  303: train_mean_reward=0.5875 (Δ +0.4195) kept_rollouts=0 skipped_problems=4\n",
      "Step  304: train_mean_reward=0.4021 (Δ -0.1854) kept_rollouts=32 skipped_problems=2\n",
      "Step  305: train_mean_reward=0.5698 (Δ +0.1676) kept_rollouts=32 skipped_problems=2\n",
      "Step  306: train_mean_reward=0.5652 (Δ -0.0045) kept_rollouts=16 skipped_problems=3\n",
      "Step  307: train_mean_reward=0.4865 (Δ -0.0788) kept_rollouts=16 skipped_problems=3\n",
      "Step  308: train_mean_reward=0.3774 (Δ -0.1090) kept_rollouts=0 skipped_problems=4\n",
      "Step  309: train_mean_reward=0.5788 (Δ +0.2013) kept_rollouts=16 skipped_problems=3\n",
      "Step  310: train_mean_reward=0.5115 (Δ -0.0673) kept_rollouts=16 skipped_problems=3\n",
      "Step  311: train_mean_reward=0.7729 (Δ +0.2614) kept_rollouts=16 skipped_problems=3\n",
      "Step  312: train_mean_reward=0.5670 (Δ -0.2059) kept_rollouts=16 skipped_problems=3\n",
      "Step  313: train_mean_reward=0.1474 (Δ -0.4196) kept_rollouts=32 skipped_problems=2\n",
      "Step  314: train_mean_reward=0.8071 (Δ +0.6597) kept_rollouts=0 skipped_problems=4\n",
      "Step  315: train_mean_reward=0.5982 (Δ -0.2089) kept_rollouts=0 skipped_problems=4\n",
      "Step  316: train_mean_reward=0.4442 (Δ -0.1540) kept_rollouts=32 skipped_problems=2\n",
      "Step  317: train_mean_reward=0.1583 (Δ -0.2859) kept_rollouts=32 skipped_problems=2\n",
      "Step  318: train_mean_reward=0.5760 (Δ +0.4177) kept_rollouts=32 skipped_problems=2\n",
      "Step  319: train_mean_reward=0.1557 (Δ -0.4204) kept_rollouts=16 skipped_problems=3\n",
      "Step  320: train_mean_reward=0.1724 (Δ +0.0168) kept_rollouts=32 skipped_problems=2\n",
      "Step  321: train_mean_reward=0.3467 (Δ +0.1742) kept_rollouts=64 skipped_problems=0\n",
      "Step  322: train_mean_reward=0.1251 (Δ -0.2216) kept_rollouts=16 skipped_problems=3\n",
      "Step  323: train_mean_reward=0.1455 (Δ +0.0205) kept_rollouts=32 skipped_problems=2\n",
      "Step  324: train_mean_reward=0.1395 (Δ -0.0061) kept_rollouts=16 skipped_problems=3\n",
      "Step  325: train_mean_reward=0.3711 (Δ +0.2316) kept_rollouts=32 skipped_problems=2\n",
      "Step  326: train_mean_reward=0.2129 (Δ -0.1581) kept_rollouts=64 skipped_problems=0\n",
      "Step  327: train_mean_reward=0.1911 (Δ -0.0218) kept_rollouts=48 skipped_problems=1\n",
      "Step  328: train_mean_reward=0.4285 (Δ +0.2374) kept_rollouts=32 skipped_problems=2\n",
      "Step  329: train_mean_reward=0.3629 (Δ -0.0656) kept_rollouts=32 skipped_problems=2\n",
      "Step  330: train_mean_reward=0.1461 (Δ -0.2168) eval_mean_reward=0.3260 ema_eval_reward=0.3103 kept_rollouts=32 skipped_problems=2\n",
      "Step  331: train_mean_reward=0.3682 (Δ +0.2221) kept_rollouts=16 skipped_problems=3\n",
      "Step  332: train_mean_reward=0.3381 (Δ -0.0301) kept_rollouts=16 skipped_problems=3\n",
      "Step  333: train_mean_reward=0.1685 (Δ -0.1696) kept_rollouts=16 skipped_problems=3\n",
      "Step  334: train_mean_reward=0.2092 (Δ +0.0406) kept_rollouts=32 skipped_problems=2\n",
      "Step  335: train_mean_reward=0.6550 (Δ +0.4458) kept_rollouts=16 skipped_problems=3\n",
      "Step  336: train_mean_reward=0.3888 (Δ -0.2662) kept_rollouts=0 skipped_problems=4\n",
      "Step  337: train_mean_reward=0.1971 (Δ -0.1917) kept_rollouts=16 skipped_problems=3\n",
      "Step  338: train_mean_reward=0.3025 (Δ +0.1054) kept_rollouts=16 skipped_problems=3\n",
      "Step  339: train_mean_reward=0.1970 (Δ -0.1055) kept_rollouts=48 skipped_problems=1\n",
      "Step  340: train_mean_reward=0.5640 (Δ +0.3670) kept_rollouts=32 skipped_problems=2\n",
      "Step  341: train_mean_reward=0.5695 (Δ +0.0055) kept_rollouts=0 skipped_problems=4\n",
      "Step  342: train_mean_reward=0.2554 (Δ -0.3141) kept_rollouts=16 skipped_problems=3\n",
      "Step  343: train_mean_reward=0.4894 (Δ +0.2339) kept_rollouts=16 skipped_problems=3\n",
      "Step  344: train_mean_reward=0.8500 (Δ +0.3606) kept_rollouts=0 skipped_problems=4\n",
      "Step  345: train_mean_reward=0.1337 (Δ -0.7163) kept_rollouts=0 skipped_problems=4\n",
      "Step  346: train_mean_reward=0.4521 (Δ +0.3185) kept_rollouts=32 skipped_problems=2\n",
      "Step  347: train_mean_reward=0.5598 (Δ +0.1076) kept_rollouts=0 skipped_problems=4\n",
      "Step  348: train_mean_reward=0.2190 (Δ -0.3407) kept_rollouts=32 skipped_problems=2\n",
      "Step  349: train_mean_reward=0.6068 (Δ +0.3878) kept_rollouts=32 skipped_problems=2\n",
      "Step  350: train_mean_reward=0.5620 (Δ -0.0448) kept_rollouts=32 skipped_problems=2\n",
      "Step  351: train_mean_reward=0.5633 (Δ +0.0013) kept_rollouts=32 skipped_problems=2\n",
      "Step  352: train_mean_reward=0.7198 (Δ +0.1565) kept_rollouts=16 skipped_problems=3\n",
      "Step  353: train_mean_reward=0.2112 (Δ -0.5087) kept_rollouts=32 skipped_problems=2\n",
      "Step  354: train_mean_reward=0.2509 (Δ +0.0398) kept_rollouts=16 skipped_problems=3\n",
      "Step  355: train_mean_reward=0.2698 (Δ +0.0189) kept_rollouts=0 skipped_problems=4\n",
      "Step  356: train_mean_reward=0.5643 (Δ +0.2945) kept_rollouts=16 skipped_problems=3\n",
      "Step  357: train_mean_reward=0.5698 (Δ +0.0055) kept_rollouts=16 skipped_problems=3\n",
      "Step  358: train_mean_reward=0.3801 (Δ -0.1897) kept_rollouts=32 skipped_problems=2\n",
      "Step  359: train_mean_reward=0.3349 (Δ -0.0452) kept_rollouts=16 skipped_problems=3\n",
      "Step  360: train_mean_reward=0.3581 (Δ +0.0233) eval_mean_reward=0.4012 ema_eval_reward=0.3194 kept_rollouts=0 skipped_problems=4\n",
      "Step  361: train_mean_reward=0.5612 (Δ +0.2030) kept_rollouts=16 skipped_problems=3\n",
      "Step  362: train_mean_reward=0.5930 (Δ +0.0318) kept_rollouts=32 skipped_problems=2\n",
      "Step  363: train_mean_reward=0.5160 (Δ -0.0770) kept_rollouts=32 skipped_problems=2\n",
      "Step  364: train_mean_reward=0.4582 (Δ -0.0578) kept_rollouts=16 skipped_problems=3\n",
      "Step  365: train_mean_reward=0.5914 (Δ +0.1332) kept_rollouts=16 skipped_problems=3\n",
      "Step  366: train_mean_reward=0.2523 (Δ -0.3391) kept_rollouts=48 skipped_problems=1\n",
      "Step  367: train_mean_reward=0.2823 (Δ +0.0301) kept_rollouts=32 skipped_problems=2\n",
      "Step  368: train_mean_reward=0.4707 (Δ +0.1884) kept_rollouts=0 skipped_problems=4\n",
      "Step  369: train_mean_reward=0.3588 (Δ -0.1119) kept_rollouts=48 skipped_problems=1\n",
      "Step  370: train_mean_reward=0.4099 (Δ +0.0511) kept_rollouts=32 skipped_problems=2\n",
      "Step  371: train_mean_reward=0.7170 (Δ +0.3071) kept_rollouts=48 skipped_problems=1\n",
      "Step  372: train_mean_reward=0.1728 (Δ -0.5442) kept_rollouts=32 skipped_problems=2\n",
      "Step  373: train_mean_reward=0.3995 (Δ +0.2266) kept_rollouts=0 skipped_problems=4\n",
      "Step  374: train_mean_reward=0.5327 (Δ +0.1332) kept_rollouts=32 skipped_problems=2\n",
      "Step  375: train_mean_reward=0.3586 (Δ -0.1741) kept_rollouts=16 skipped_problems=3\n",
      "Step  376: train_mean_reward=0.2288 (Δ -0.1298) kept_rollouts=16 skipped_problems=3\n",
      "Step  377: train_mean_reward=0.4494 (Δ +0.2206) kept_rollouts=16 skipped_problems=3\n",
      "Step  378: train_mean_reward=0.5470 (Δ +0.0976) kept_rollouts=16 skipped_problems=3\n",
      "Step  379: train_mean_reward=0.3435 (Δ -0.2035) kept_rollouts=16 skipped_problems=3\n",
      "Step  380: train_mean_reward=0.2834 (Δ -0.0601) kept_rollouts=32 skipped_problems=2\n",
      "Step  381: train_mean_reward=0.3786 (Δ +0.0952) kept_rollouts=16 skipped_problems=3\n",
      "Step  382: train_mean_reward=0.3705 (Δ -0.0081) kept_rollouts=16 skipped_problems=3\n",
      "Step  383: train_mean_reward=0.3575 (Δ -0.0130) kept_rollouts=16 skipped_problems=3\n",
      "Step  384: train_mean_reward=0.3783 (Δ +0.0208) kept_rollouts=16 skipped_problems=3\n",
      "Step  385: train_mean_reward=0.3422 (Δ -0.0361) kept_rollouts=32 skipped_problems=2\n",
      "Step  386: train_mean_reward=0.3897 (Δ +0.0475) kept_rollouts=32 skipped_problems=2\n",
      "Step  387: train_mean_reward=0.7268 (Δ +0.3371) kept_rollouts=16 skipped_problems=3\n",
      "Step  388: train_mean_reward=0.2822 (Δ -0.4446) kept_rollouts=0 skipped_problems=4\n",
      "Step  389: train_mean_reward=0.1903 (Δ -0.0919) kept_rollouts=48 skipped_problems=1\n",
      "Step  390: train_mean_reward=0.5668 (Δ +0.3764) eval_mean_reward=0.4926 ema_eval_reward=0.3367 kept_rollouts=0 skipped_problems=4\n",
      "Step  391: train_mean_reward=0.4621 (Δ -0.1046) kept_rollouts=0 skipped_problems=4\n",
      "Step  392: train_mean_reward=0.5729 (Δ +0.1108) kept_rollouts=16 skipped_problems=3\n",
      "Step  393: train_mean_reward=0.2941 (Δ -0.2788) kept_rollouts=16 skipped_problems=3\n",
      "Step  394: train_mean_reward=0.2927 (Δ -0.0014) kept_rollouts=16 skipped_problems=3\n",
      "Step  395: train_mean_reward=0.6700 (Δ +0.3773) kept_rollouts=0 skipped_problems=4\n",
      "Step  396: train_mean_reward=0.1450 (Δ -0.5250) kept_rollouts=32 skipped_problems=2\n",
      "Step  397: train_mean_reward=0.3005 (Δ +0.1555) kept_rollouts=48 skipped_problems=1\n",
      "Step  398: train_mean_reward=0.4791 (Δ +0.1786) kept_rollouts=32 skipped_problems=2\n",
      "Step  399: train_mean_reward=0.2191 (Δ -0.2601) kept_rollouts=16 skipped_problems=3\n",
      "Step  400: train_mean_reward=0.3396 (Δ +0.1206) kept_rollouts=32 skipped_problems=2\n",
      "Step  401: train_mean_reward=0.2506 (Δ -0.0891) kept_rollouts=48 skipped_problems=1\n",
      "Step  402: train_mean_reward=0.4297 (Δ +0.1791) kept_rollouts=64 skipped_problems=0\n",
      "Step  403: train_mean_reward=0.4238 (Δ -0.0059) kept_rollouts=32 skipped_problems=2\n",
      "Step  404: train_mean_reward=0.3583 (Δ -0.0655) kept_rollouts=0 skipped_problems=4\n",
      "Step  405: train_mean_reward=0.3443 (Δ -0.0139) kept_rollouts=48 skipped_problems=1\n",
      "Step  406: train_mean_reward=0.7503 (Δ +0.4060) kept_rollouts=32 skipped_problems=2\n",
      "Step  407: train_mean_reward=0.1424 (Δ -0.6079) kept_rollouts=32 skipped_problems=2\n",
      "Step  408: train_mean_reward=0.3467 (Δ +0.2043) kept_rollouts=0 skipped_problems=4\n",
      "Step  409: train_mean_reward=0.2007 (Δ -0.1460) kept_rollouts=32 skipped_problems=2\n",
      "Step  410: train_mean_reward=0.2499 (Δ +0.0493) kept_rollouts=32 skipped_problems=2\n",
      "Step  411: train_mean_reward=0.1285 (Δ -0.1215) kept_rollouts=48 skipped_problems=1\n",
      "Step  412: train_mean_reward=0.1347 (Δ +0.0062) kept_rollouts=16 skipped_problems=3\n",
      "Step  413: train_mean_reward=0.3477 (Δ +0.2130) kept_rollouts=16 skipped_problems=3\n",
      "Step  414: train_mean_reward=0.3520 (Δ +0.0043) kept_rollouts=0 skipped_problems=4\n",
      "Step  415: train_mean_reward=0.3871 (Δ +0.0351) kept_rollouts=48 skipped_problems=1\n",
      "Step  416: train_mean_reward=0.6137 (Δ +0.2266) kept_rollouts=32 skipped_problems=2\n",
      "Step  417: train_mean_reward=0.3535 (Δ -0.2603) kept_rollouts=16 skipped_problems=3\n",
      "Step  418: train_mean_reward=0.5674 (Δ +0.2140) kept_rollouts=32 skipped_problems=2\n",
      "Step  419: train_mean_reward=0.3428 (Δ -0.2247) kept_rollouts=48 skipped_problems=1\n",
      "Step  420: train_mean_reward=0.3715 (Δ +0.0287) eval_mean_reward=0.4521 ema_eval_reward=0.3483 kept_rollouts=32 skipped_problems=2\n",
      "Step  421: train_mean_reward=0.4450 (Δ +0.0735) kept_rollouts=32 skipped_problems=2\n",
      "Step  422: train_mean_reward=0.1280 (Δ -0.3170) kept_rollouts=32 skipped_problems=2\n",
      "Step  423: train_mean_reward=0.4469 (Δ +0.3189) kept_rollouts=16 skipped_problems=3\n",
      "Step  424: train_mean_reward=0.7814 (Δ +0.3345) kept_rollouts=0 skipped_problems=4\n",
      "Step  425: train_mean_reward=0.5493 (Δ -0.2321) kept_rollouts=16 skipped_problems=3\n",
      "Step  426: train_mean_reward=0.4095 (Δ -0.1398) kept_rollouts=48 skipped_problems=1\n",
      "Step  427: train_mean_reward=0.2048 (Δ -0.2046) kept_rollouts=48 skipped_problems=1\n",
      "Step  428: train_mean_reward=0.5698 (Δ +0.3649) kept_rollouts=0 skipped_problems=4\n",
      "Step  429: train_mean_reward=0.5859 (Δ +0.0161) kept_rollouts=16 skipped_problems=3\n",
      "Step  430: train_mean_reward=0.2961 (Δ -0.2898) kept_rollouts=0 skipped_problems=4\n",
      "Step  431: train_mean_reward=0.8356 (Δ +0.5395) kept_rollouts=16 skipped_problems=3\n",
      "Step  432: train_mean_reward=0.3287 (Δ -0.5069) kept_rollouts=16 skipped_problems=3\n",
      "Step  433: train_mean_reward=0.3577 (Δ +0.0289) kept_rollouts=16 skipped_problems=3\n",
      "Step  434: train_mean_reward=0.1835 (Δ -0.1742) kept_rollouts=0 skipped_problems=4\n",
      "Step  435: train_mean_reward=0.4221 (Δ +0.2386) kept_rollouts=16 skipped_problems=3\n",
      "Step  436: train_mean_reward=0.4074 (Δ -0.0147) kept_rollouts=16 skipped_problems=3\n",
      "Step  437: train_mean_reward=0.3731 (Δ -0.0343) kept_rollouts=32 skipped_problems=2\n",
      "Step  438: train_mean_reward=0.4854 (Δ +0.1123) kept_rollouts=16 skipped_problems=3\n",
      "Step  439: train_mean_reward=0.5821 (Δ +0.0967) kept_rollouts=0 skipped_problems=4\n",
      "Step  440: train_mean_reward=0.2496 (Δ -0.3325) kept_rollouts=0 skipped_problems=4\n",
      "Step  441: train_mean_reward=0.5266 (Δ +0.2769) kept_rollouts=32 skipped_problems=2\n",
      "Step  442: train_mean_reward=0.1518 (Δ -0.3748) kept_rollouts=32 skipped_problems=2\n",
      "Step  443: train_mean_reward=0.1433 (Δ -0.0085) kept_rollouts=32 skipped_problems=2\n",
      "Step  444: train_mean_reward=0.5978 (Δ +0.4545) kept_rollouts=16 skipped_problems=3\n",
      "Step  445: train_mean_reward=0.3687 (Δ -0.2291) kept_rollouts=16 skipped_problems=3\n",
      "Step  446: train_mean_reward=0.7868 (Δ +0.4181) kept_rollouts=0 skipped_problems=4\n",
      "Step  447: train_mean_reward=0.3272 (Δ -0.4597) kept_rollouts=48 skipped_problems=1\n",
      "Step  448: train_mean_reward=0.3583 (Δ +0.0311) kept_rollouts=48 skipped_problems=1\n",
      "Step  449: train_mean_reward=0.4687 (Δ +0.1104) kept_rollouts=0 skipped_problems=4\n",
      "Step  450: train_mean_reward=0.2434 (Δ -0.2252) eval_mean_reward=0.3338 ema_eval_reward=0.3468 kept_rollouts=0 skipped_problems=4\n",
      "Step  451: train_mean_reward=0.1475 (Δ -0.0959) kept_rollouts=32 skipped_problems=2\n",
      "Step  452: train_mean_reward=0.2538 (Δ +0.1063) kept_rollouts=0 skipped_problems=4\n",
      "Step  453: train_mean_reward=0.3639 (Δ +0.1101) kept_rollouts=0 skipped_problems=4\n",
      "Step  454: train_mean_reward=0.3726 (Δ +0.0087) kept_rollouts=16 skipped_problems=3\n",
      "Step  455: train_mean_reward=0.8000 (Δ +0.4274) kept_rollouts=0 skipped_problems=4\n",
      "Step  456: train_mean_reward=0.5695 (Δ -0.2305) kept_rollouts=16 skipped_problems=3\n",
      "Step  457: train_mean_reward=0.2647 (Δ -0.3048) kept_rollouts=0 skipped_problems=4\n",
      "Step  458: train_mean_reward=0.2188 (Δ -0.0458) kept_rollouts=48 skipped_problems=1\n",
      "Step  459: train_mean_reward=0.4211 (Δ +0.2023) kept_rollouts=32 skipped_problems=2\n",
      "Step  460: train_mean_reward=0.2954 (Δ -0.1257) kept_rollouts=64 skipped_problems=0\n",
      "Step  461: train_mean_reward=0.3769 (Δ +0.0814) kept_rollouts=16 skipped_problems=3\n",
      "Step  462: train_mean_reward=0.7638 (Δ +0.3869) kept_rollouts=32 skipped_problems=2\n",
      "Step  463: train_mean_reward=0.6111 (Δ -0.1527) kept_rollouts=0 skipped_problems=4\n",
      "Step  464: train_mean_reward=0.2652 (Δ -0.3459) kept_rollouts=16 skipped_problems=3\n",
      "Step  465: train_mean_reward=0.4086 (Δ +0.1434) kept_rollouts=32 skipped_problems=2\n",
      "Step  466: train_mean_reward=0.3877 (Δ -0.0209) kept_rollouts=32 skipped_problems=2\n",
      "Step  467: train_mean_reward=0.3687 (Δ -0.0190) kept_rollouts=16 skipped_problems=3\n",
      "Step  468: train_mean_reward=0.2533 (Δ -0.1154) kept_rollouts=32 skipped_problems=2\n",
      "Step  469: train_mean_reward=0.5772 (Δ +0.3239) kept_rollouts=32 skipped_problems=2\n",
      "Step  470: train_mean_reward=0.6090 (Δ +0.0318) kept_rollouts=16 skipped_problems=3\n",
      "Step  471: train_mean_reward=0.1373 (Δ -0.4718) kept_rollouts=0 skipped_problems=4\n",
      "Step  472: train_mean_reward=0.3443 (Δ +0.2071) kept_rollouts=32 skipped_problems=2\n",
      "Step  473: train_mean_reward=0.4249 (Δ +0.0805) kept_rollouts=16 skipped_problems=3\n",
      "Step  474: train_mean_reward=0.1515 (Δ -0.2734) kept_rollouts=16 skipped_problems=3\n",
      "Step  475: train_mean_reward=0.1461 (Δ -0.0053) kept_rollouts=32 skipped_problems=2\n",
      "Step  476: train_mean_reward=0.2466 (Δ +0.1004) kept_rollouts=16 skipped_problems=3\n",
      "Step  477: train_mean_reward=0.6745 (Δ +0.4280) kept_rollouts=16 skipped_problems=3\n",
      "Step  478: train_mean_reward=0.1619 (Δ -0.5126) kept_rollouts=0 skipped_problems=4\n",
      "Step  479: train_mean_reward=0.1858 (Δ +0.0239) kept_rollouts=16 skipped_problems=3\n",
      "Step  480: train_mean_reward=0.6159 (Δ +0.4301) eval_mean_reward=0.4151 ema_eval_reward=0.3537 kept_rollouts=16 skipped_problems=3\n",
      "Step  481: train_mean_reward=0.3093 (Δ -0.3065) kept_rollouts=16 skipped_problems=3\n",
      "Step  482: train_mean_reward=0.6580 (Δ +0.3486) kept_rollouts=16 skipped_problems=3\n",
      "Step  483: train_mean_reward=0.2277 (Δ -0.4302) kept_rollouts=48 skipped_problems=1\n",
      "Step  484: train_mean_reward=0.3573 (Δ +0.1296) kept_rollouts=48 skipped_problems=1\n",
      "Step  485: train_mean_reward=0.3428 (Δ -0.0145) kept_rollouts=32 skipped_problems=2\n",
      "Step  486: train_mean_reward=0.2564 (Δ -0.0864) kept_rollouts=16 skipped_problems=3\n",
      "Step  487: train_mean_reward=0.3784 (Δ +0.1220) kept_rollouts=0 skipped_problems=4\n",
      "Step  488: train_mean_reward=0.7951 (Δ +0.4167) kept_rollouts=32 skipped_problems=2\n",
      "Step  489: train_mean_reward=0.5601 (Δ -0.2350) kept_rollouts=48 skipped_problems=1\n",
      "Step  490: train_mean_reward=0.5142 (Δ -0.0458) kept_rollouts=0 skipped_problems=4\n",
      "Step  491: train_mean_reward=0.3467 (Δ -0.1675) kept_rollouts=0 skipped_problems=4\n",
      "Step  492: train_mean_reward=0.1266 (Δ -0.2201) kept_rollouts=48 skipped_problems=1\n",
      "Step  493: train_mean_reward=0.5687 (Δ +0.4421) kept_rollouts=16 skipped_problems=3\n",
      "Step  494: train_mean_reward=0.2376 (Δ -0.3311) kept_rollouts=16 skipped_problems=3\n",
      "Step  495: train_mean_reward=0.3501 (Δ +0.1124) kept_rollouts=16 skipped_problems=3\n",
      "Step  496: train_mean_reward=0.2921 (Δ -0.0580) kept_rollouts=48 skipped_problems=1\n",
      "Step  497: train_mean_reward=0.3869 (Δ +0.0948) kept_rollouts=0 skipped_problems=4\n",
      "Step  498: train_mean_reward=0.3862 (Δ -0.0007) kept_rollouts=0 skipped_problems=4\n",
      "Step  499: train_mean_reward=0.3320 (Δ -0.0542) kept_rollouts=48 skipped_problems=1\n",
      "Step  500: train_mean_reward=0.4308 (Δ +0.0989) kept_rollouts=0 skipped_problems=4\n",
      "Step  501: train_mean_reward=0.7737 (Δ +0.3428) kept_rollouts=16 skipped_problems=3\n",
      "Step  502: train_mean_reward=0.3120 (Δ -0.4616) kept_rollouts=16 skipped_problems=3\n",
      "Step  503: train_mean_reward=0.3910 (Δ +0.0789) kept_rollouts=16 skipped_problems=3\n",
      "Step  504: train_mean_reward=0.4482 (Δ +0.0572) kept_rollouts=16 skipped_problems=3\n",
      "Step  505: train_mean_reward=0.1273 (Δ -0.3209) kept_rollouts=0 skipped_problems=4\n",
      "Step  506: train_mean_reward=0.5527 (Δ +0.4254) kept_rollouts=16 skipped_problems=3\n",
      "Step  507: train_mean_reward=0.3724 (Δ -0.1803) kept_rollouts=32 skipped_problems=2\n",
      "Step  508: train_mean_reward=0.3532 (Δ -0.0192) kept_rollouts=0 skipped_problems=4\n",
      "Step  509: train_mean_reward=0.1568 (Δ -0.1964) kept_rollouts=16 skipped_problems=3\n",
      "Step  510: train_mean_reward=0.3196 (Δ +0.1629) eval_mean_reward=0.4030 ema_eval_reward=0.3586 kept_rollouts=16 skipped_problems=3\n",
      "Step  511: train_mean_reward=0.1418 (Δ -0.1778) kept_rollouts=32 skipped_problems=2\n",
      "Step  512: train_mean_reward=0.4522 (Δ +0.3103) kept_rollouts=32 skipped_problems=2\n",
      "Step  513: train_mean_reward=0.3792 (Δ -0.0730) kept_rollouts=16 skipped_problems=3\n",
      "Step  514: train_mean_reward=0.1628 (Δ -0.2164) kept_rollouts=32 skipped_problems=2\n",
      "Step  515: train_mean_reward=0.5871 (Δ +0.4244) kept_rollouts=0 skipped_problems=4\n",
      "Step  516: train_mean_reward=0.1398 (Δ -0.4473) kept_rollouts=48 skipped_problems=1\n",
      "Step  517: train_mean_reward=0.2711 (Δ +0.1313) kept_rollouts=16 skipped_problems=3\n",
      "Step  518: train_mean_reward=0.5766 (Δ +0.3055) kept_rollouts=16 skipped_problems=3\n",
      "Step  519: train_mean_reward=0.3560 (Δ -0.2206) kept_rollouts=32 skipped_problems=2\n",
      "Step  520: train_mean_reward=0.3645 (Δ +0.0084) kept_rollouts=16 skipped_problems=3\n",
      "Step  521: train_mean_reward=0.3983 (Δ +0.0338) kept_rollouts=0 skipped_problems=4\n",
      "Step  522: train_mean_reward=0.1816 (Δ -0.2167) kept_rollouts=16 skipped_problems=3\n",
      "Step  523: train_mean_reward=0.3647 (Δ +0.1830) kept_rollouts=16 skipped_problems=3\n",
      "Step  524: train_mean_reward=0.5686 (Δ +0.2039) kept_rollouts=16 skipped_problems=3\n",
      "Step  525: train_mean_reward=0.3369 (Δ -0.2317) kept_rollouts=32 skipped_problems=2\n",
      "Step  526: train_mean_reward=0.4819 (Δ +0.1450) kept_rollouts=48 skipped_problems=1\n",
      "Step  527: train_mean_reward=0.6349 (Δ +0.1530) kept_rollouts=32 skipped_problems=2\n",
      "Step  528: train_mean_reward=0.3019 (Δ -0.3330) kept_rollouts=48 skipped_problems=1\n",
      "Step  529: train_mean_reward=0.4447 (Δ +0.1428) kept_rollouts=48 skipped_problems=1\n",
      "Step  530: train_mean_reward=0.1331 (Δ -0.3115) kept_rollouts=48 skipped_problems=1\n",
      "Step  531: train_mean_reward=0.5637 (Δ +0.4306) kept_rollouts=32 skipped_problems=2\n",
      "Step  532: train_mean_reward=0.1845 (Δ -0.3793) kept_rollouts=32 skipped_problems=2\n",
      "Step  533: train_mean_reward=0.2166 (Δ +0.0321) kept_rollouts=48 skipped_problems=1\n",
      "Step  534: train_mean_reward=0.6050 (Δ +0.3884) kept_rollouts=32 skipped_problems=2\n",
      "Step  535: train_mean_reward=0.4390 (Δ -0.1660) kept_rollouts=48 skipped_problems=1\n",
      "Step  536: train_mean_reward=0.3581 (Δ -0.0809) kept_rollouts=32 skipped_problems=2\n",
      "Step  537: train_mean_reward=0.3752 (Δ +0.0171) kept_rollouts=32 skipped_problems=2\n",
      "Step  538: train_mean_reward=0.3637 (Δ -0.0115) kept_rollouts=16 skipped_problems=3\n",
      "Step  539: train_mean_reward=0.1263 (Δ -0.2374) kept_rollouts=48 skipped_problems=1\n",
      "Step  540: train_mean_reward=0.3568 (Δ +0.2305) eval_mean_reward=0.3870 ema_eval_reward=0.3614 kept_rollouts=32 skipped_problems=2\n",
      "Step  541: train_mean_reward=0.2352 (Δ -0.1216) kept_rollouts=16 skipped_problems=3\n",
      "Step  542: train_mean_reward=0.1489 (Δ -0.0863) kept_rollouts=48 skipped_problems=1\n",
      "Step  543: train_mean_reward=0.5737 (Δ +0.4249) kept_rollouts=0 skipped_problems=4\n",
      "Step  544: train_mean_reward=0.5044 (Δ -0.0694) kept_rollouts=48 skipped_problems=1\n",
      "Step  545: train_mean_reward=0.7696 (Δ +0.2653) kept_rollouts=32 skipped_problems=2\n",
      "Step  546: train_mean_reward=0.3788 (Δ -0.3908) kept_rollouts=16 skipped_problems=3\n",
      "Step  547: train_mean_reward=0.4957 (Δ +0.1168) kept_rollouts=16 skipped_problems=3\n",
      "Step  548: train_mean_reward=0.1871 (Δ -0.3086) kept_rollouts=32 skipped_problems=2\n",
      "Step  549: train_mean_reward=0.3542 (Δ +0.1671) kept_rollouts=0 skipped_problems=4\n",
      "Step  550: train_mean_reward=0.5114 (Δ +0.1572) kept_rollouts=32 skipped_problems=2\n",
      "Step  551: train_mean_reward=0.5762 (Δ +0.0648) kept_rollouts=0 skipped_problems=4\n",
      "Step  552: train_mean_reward=0.3816 (Δ -0.1946) kept_rollouts=32 skipped_problems=2\n",
      "Step  553: train_mean_reward=0.6250 (Δ +0.2434) kept_rollouts=0 skipped_problems=4\n",
      "Step  554: train_mean_reward=0.2959 (Δ -0.3291) kept_rollouts=32 skipped_problems=2\n",
      "Step  555: train_mean_reward=0.4517 (Δ +0.1557) kept_rollouts=48 skipped_problems=1\n",
      "Step  556: train_mean_reward=0.2587 (Δ -0.1929) kept_rollouts=16 skipped_problems=3\n",
      "Step  557: train_mean_reward=0.7816 (Δ +0.5228) kept_rollouts=16 skipped_problems=3\n",
      "Step  558: train_mean_reward=0.5286 (Δ -0.2530) kept_rollouts=32 skipped_problems=2\n",
      "Step  559: train_mean_reward=0.9595 (Δ +0.4309) kept_rollouts=16 skipped_problems=3\n",
      "Step  560: train_mean_reward=0.3476 (Δ -0.6119) kept_rollouts=32 skipped_problems=2\n",
      "Step  561: train_mean_reward=0.5789 (Δ +0.2313) kept_rollouts=0 skipped_problems=4\n",
      "Step  562: train_mean_reward=0.1471 (Δ -0.4318) kept_rollouts=48 skipped_problems=1\n",
      "Step  563: train_mean_reward=0.2398 (Δ +0.0927) kept_rollouts=32 skipped_problems=2\n",
      "Step  564: train_mean_reward=0.3688 (Δ +0.1290) kept_rollouts=0 skipped_problems=4\n",
      "Step  565: train_mean_reward=0.2645 (Δ -0.1043) kept_rollouts=16 skipped_problems=3\n",
      "Step  566: train_mean_reward=0.3996 (Δ +0.1351) kept_rollouts=32 skipped_problems=2\n",
      "Step  567: train_mean_reward=0.2922 (Δ -0.1073) kept_rollouts=64 skipped_problems=0\n",
      "Step  568: train_mean_reward=0.2311 (Δ -0.0611) kept_rollouts=32 skipped_problems=2\n",
      "Step  569: train_mean_reward=0.1866 (Δ -0.0445) kept_rollouts=16 skipped_problems=3\n",
      "Step  570: train_mean_reward=0.1446 (Δ -0.0420) eval_mean_reward=0.4083 ema_eval_reward=0.3661 kept_rollouts=64 skipped_problems=0\n",
      "Step  571: train_mean_reward=0.4482 (Δ +0.3036) kept_rollouts=16 skipped_problems=3\n",
      "Step  572: train_mean_reward=0.1823 (Δ -0.2659) kept_rollouts=32 skipped_problems=2\n",
      "Step  573: train_mean_reward=0.3707 (Δ +0.1884) kept_rollouts=32 skipped_problems=2\n",
      "Step  574: train_mean_reward=0.4015 (Δ +0.0308) kept_rollouts=0 skipped_problems=4\n",
      "Step  575: train_mean_reward=0.6077 (Δ +0.2062) kept_rollouts=16 skipped_problems=3\n",
      "Step  576: train_mean_reward=0.4001 (Δ -0.2076) kept_rollouts=32 skipped_problems=2\n",
      "Step  577: train_mean_reward=0.3405 (Δ -0.0596) kept_rollouts=48 skipped_problems=1\n",
      "Step  578: train_mean_reward=0.8875 (Δ +0.5470) kept_rollouts=0 skipped_problems=4\n",
      "Step  579: train_mean_reward=0.1596 (Δ -0.7279) kept_rollouts=0 skipped_problems=4\n",
      "Step  580: train_mean_reward=0.3833 (Δ +0.2237) kept_rollouts=0 skipped_problems=4\n",
      "Step  581: train_mean_reward=0.1907 (Δ -0.1926) kept_rollouts=48 skipped_problems=1\n",
      "Step  582: train_mean_reward=0.3741 (Δ +0.1833) kept_rollouts=16 skipped_problems=3\n",
      "Step  583: train_mean_reward=0.3923 (Δ +0.0182) kept_rollouts=48 skipped_problems=1\n",
      "Step  584: train_mean_reward=0.3556 (Δ -0.0367) kept_rollouts=16 skipped_problems=3\n",
      "Step  585: train_mean_reward=0.5210 (Δ +0.1654) kept_rollouts=32 skipped_problems=2\n",
      "Step  586: train_mean_reward=0.2225 (Δ -0.2985) kept_rollouts=32 skipped_problems=2\n",
      "Step  587: train_mean_reward=0.5585 (Δ +0.3360) kept_rollouts=16 skipped_problems=3\n",
      "Step  588: train_mean_reward=0.6727 (Δ +0.1142) kept_rollouts=32 skipped_problems=2\n",
      "Step  589: train_mean_reward=0.1633 (Δ -0.5094) kept_rollouts=48 skipped_problems=1\n",
      "Step  590: train_mean_reward=0.3718 (Δ +0.2085) kept_rollouts=16 skipped_problems=3\n",
      "Step  591: train_mean_reward=0.5553 (Δ +0.1835) kept_rollouts=32 skipped_problems=2\n",
      "Step  592: train_mean_reward=0.3749 (Δ -0.1804) kept_rollouts=32 skipped_problems=2\n",
      "Step  593: train_mean_reward=0.1850 (Δ -0.1899) kept_rollouts=16 skipped_problems=3\n",
      "Step  594: train_mean_reward=0.2839 (Δ +0.0989) kept_rollouts=32 skipped_problems=2\n",
      "Step  595: train_mean_reward=0.1607 (Δ -0.1232) kept_rollouts=32 skipped_problems=2\n",
      "Step  596: train_mean_reward=0.7976 (Δ +0.6369) kept_rollouts=16 skipped_problems=3\n",
      "Step  597: train_mean_reward=0.4431 (Δ -0.3545) kept_rollouts=0 skipped_problems=4\n",
      "Step  598: train_mean_reward=0.6143 (Δ +0.1712) kept_rollouts=0 skipped_problems=4\n",
      "Step  599: train_mean_reward=0.2173 (Δ -0.3970) kept_rollouts=48 skipped_problems=1\n",
      "Step  600: train_mean_reward=0.1526 (Δ -0.0647) eval_mean_reward=0.4234 ema_eval_reward=0.3718 kept_rollouts=32 skipped_problems=2\n",
      "Step  601: train_mean_reward=0.3531 (Δ +0.2005) kept_rollouts=16 skipped_problems=3\n",
      "Step  602: train_mean_reward=0.1610 (Δ -0.1922) kept_rollouts=0 skipped_problems=4\n",
      "Step  603: train_mean_reward=0.7975 (Δ +0.6365) kept_rollouts=0 skipped_problems=4\n",
      "Step  604: train_mean_reward=0.2351 (Δ -0.5624) kept_rollouts=16 skipped_problems=3\n",
      "Step  605: train_mean_reward=0.4849 (Δ +0.2498) kept_rollouts=48 skipped_problems=1\n",
      "Step  606: train_mean_reward=0.4852 (Δ +0.0003) kept_rollouts=0 skipped_problems=4\n",
      "Step  607: train_mean_reward=0.1382 (Δ -0.3470) kept_rollouts=0 skipped_problems=4\n",
      "Step  608: train_mean_reward=0.8875 (Δ +0.7493) kept_rollouts=0 skipped_problems=4\n",
      "Step  609: train_mean_reward=0.5691 (Δ -0.3184) kept_rollouts=0 skipped_problems=4\n",
      "Step  610: train_mean_reward=0.4156 (Δ -0.1535) kept_rollouts=0 skipped_problems=4\n",
      "Step  611: train_mean_reward=0.1436 (Δ -0.2720) kept_rollouts=0 skipped_problems=4\n",
      "Step  612: train_mean_reward=0.3549 (Δ +0.2114) kept_rollouts=16 skipped_problems=3\n",
      "Step  613: train_mean_reward=0.1535 (Δ -0.2015) kept_rollouts=0 skipped_problems=4\n",
      "Step  614: train_mean_reward=0.3926 (Δ +0.2392) kept_rollouts=16 skipped_problems=3\n",
      "Step  615: train_mean_reward=0.6250 (Δ +0.2324) kept_rollouts=0 skipped_problems=4\n",
      "Step  616: train_mean_reward=0.6906 (Δ +0.0656) kept_rollouts=0 skipped_problems=4\n",
      "Step  617: train_mean_reward=0.5573 (Δ -0.1334) kept_rollouts=0 skipped_problems=4\n",
      "Step  618: train_mean_reward=0.3320 (Δ -0.2253) kept_rollouts=0 skipped_problems=4\n",
      "Step  619: train_mean_reward=0.2828 (Δ -0.0491) kept_rollouts=0 skipped_problems=4\n",
      "Step  620: train_mean_reward=0.6231 (Δ +0.3403) kept_rollouts=0 skipped_problems=4\n",
      "Step  621: train_mean_reward=0.4442 (Δ -0.1789) kept_rollouts=0 skipped_problems=4\n",
      "Step  622: train_mean_reward=0.3792 (Δ -0.0650) kept_rollouts=48 skipped_problems=1\n",
      "Step  623: train_mean_reward=0.7863 (Δ +0.4070) kept_rollouts=0 skipped_problems=4\n",
      "Step  624: train_mean_reward=0.2764 (Δ -0.5099) kept_rollouts=16 skipped_problems=3\n",
      "Step  625: train_mean_reward=0.1844 (Δ -0.0920) kept_rollouts=0 skipped_problems=4\n",
      "Step  626: train_mean_reward=0.1367 (Δ -0.0478) kept_rollouts=0 skipped_problems=4\n",
      "Step  627: train_mean_reward=0.5358 (Δ +0.3992) kept_rollouts=32 skipped_problems=2\n",
      "Step  628: train_mean_reward=0.6031 (Δ +0.0673) kept_rollouts=0 skipped_problems=4\n",
      "Step  629: train_mean_reward=0.4147 (Δ -0.1884) kept_rollouts=16 skipped_problems=3\n",
      "Step  630: train_mean_reward=0.1671 (Δ -0.2476) eval_mean_reward=0.3984 ema_eval_reward=0.3745 kept_rollouts=16 skipped_problems=3\n",
      "Step  631: train_mean_reward=0.1950 (Δ +0.0279) kept_rollouts=16 skipped_problems=3\n",
      "Step  632: train_mean_reward=0.3602 (Δ +0.1652) kept_rollouts=32 skipped_problems=2\n",
      "Step  633: train_mean_reward=0.4202 (Δ +0.0600) kept_rollouts=32 skipped_problems=2\n",
      "Step  634: train_mean_reward=0.2198 (Δ -0.2004) kept_rollouts=0 skipped_problems=4\n",
      "Step  635: train_mean_reward=0.5687 (Δ +0.3490) kept_rollouts=0 skipped_problems=4\n",
      "Step  636: train_mean_reward=0.3527 (Δ -0.2161) kept_rollouts=0 skipped_problems=4\n",
      "Step  637: train_mean_reward=0.1334 (Δ -0.2192) kept_rollouts=16 skipped_problems=3\n",
      "Step  638: train_mean_reward=0.4105 (Δ +0.2770) kept_rollouts=16 skipped_problems=3\n",
      "Step  639: train_mean_reward=0.1301 (Δ -0.2804) kept_rollouts=0 skipped_problems=4\n",
      "Step  640: train_mean_reward=0.3455 (Δ +0.2154) kept_rollouts=0 skipped_problems=4\n",
      "Step  641: train_mean_reward=0.3657 (Δ +0.0203) kept_rollouts=32 skipped_problems=2\n",
      "Step  642: train_mean_reward=0.5687 (Δ +0.2030) kept_rollouts=0 skipped_problems=4\n",
      "Step  643: train_mean_reward=0.1557 (Δ -0.4130) kept_rollouts=0 skipped_problems=4\n",
      "Step  644: train_mean_reward=0.3590 (Δ +0.2033) kept_rollouts=16 skipped_problems=3\n",
      "Step  645: train_mean_reward=0.4183 (Δ +0.0593) kept_rollouts=16 skipped_problems=3\n",
      "Step  646: train_mean_reward=0.3426 (Δ -0.0757) kept_rollouts=0 skipped_problems=4\n",
      "Step  647: train_mean_reward=0.1173 (Δ -0.2254) kept_rollouts=16 skipped_problems=3\n",
      "Step  648: train_mean_reward=0.3689 (Δ +0.2516) kept_rollouts=16 skipped_problems=3\n",
      "Step  649: train_mean_reward=0.3886 (Δ +0.0197) kept_rollouts=0 skipped_problems=4\n",
      "Step  650: train_mean_reward=0.5670 (Δ +0.1784) kept_rollouts=0 skipped_problems=4\n",
      "Step  651: train_mean_reward=0.3687 (Δ -0.1983) kept_rollouts=0 skipped_problems=4\n",
      "Step  652: train_mean_reward=0.5817 (Δ +0.2130) kept_rollouts=0 skipped_problems=4\n",
      "Step  653: train_mean_reward=0.2481 (Δ -0.3336) kept_rollouts=16 skipped_problems=3\n",
      "Step  654: train_mean_reward=0.1962 (Δ -0.0519) kept_rollouts=16 skipped_problems=3\n",
      "Step  655: train_mean_reward=0.3883 (Δ +0.1921) kept_rollouts=16 skipped_problems=3\n",
      "Step  656: train_mean_reward=0.3865 (Δ -0.0018) kept_rollouts=16 skipped_problems=3\n",
      "Step  657: train_mean_reward=0.4606 (Δ +0.0741) kept_rollouts=16 skipped_problems=3\n",
      "Step  658: train_mean_reward=0.1955 (Δ -0.2651) kept_rollouts=0 skipped_problems=4\n",
      "Step  659: train_mean_reward=0.3076 (Δ +0.1120) kept_rollouts=32 skipped_problems=2\n",
      "Step  660: train_mean_reward=0.1652 (Δ -0.1424) eval_mean_reward=0.4398 ema_eval_reward=0.3810 kept_rollouts=32 skipped_problems=2\n",
      "Step  661: train_mean_reward=0.3483 (Δ +0.1831) kept_rollouts=0 skipped_problems=4\n",
      "Step  662: train_mean_reward=0.3461 (Δ -0.0022) kept_rollouts=0 skipped_problems=4\n",
      "Step  663: train_mean_reward=0.2794 (Δ -0.0667) kept_rollouts=0 skipped_problems=4\n",
      "Step  664: train_mean_reward=0.1524 (Δ -0.1270) kept_rollouts=0 skipped_problems=4\n",
      "Step  665: train_mean_reward=0.3799 (Δ +0.2275) kept_rollouts=16 skipped_problems=3\n",
      "Step  666: train_mean_reward=0.5332 (Δ +0.1533) kept_rollouts=16 skipped_problems=3\n",
      "Step  667: train_mean_reward=0.1562 (Δ -0.3770) kept_rollouts=0 skipped_problems=4\n",
      "Step  668: train_mean_reward=0.3473 (Δ +0.1911) kept_rollouts=16 skipped_problems=3\n",
      "Step  669: train_mean_reward=0.6080 (Δ +0.2607) kept_rollouts=0 skipped_problems=4\n",
      "Step  670: train_mean_reward=0.4562 (Δ -0.1517) kept_rollouts=0 skipped_problems=4\n",
      "Step  671: train_mean_reward=0.8251 (Δ +0.3689) kept_rollouts=16 skipped_problems=3\n",
      "Step  672: train_mean_reward=0.4493 (Δ -0.3759) kept_rollouts=0 skipped_problems=4\n",
      "Step  673: train_mean_reward=0.1845 (Δ -0.2647) kept_rollouts=0 skipped_problems=4\n",
      "Step  674: train_mean_reward=0.3587 (Δ +0.1742) kept_rollouts=0 skipped_problems=4\n",
      "Step  675: train_mean_reward=0.6586 (Δ +0.2999) kept_rollouts=16 skipped_problems=3\n",
      "Step  676: train_mean_reward=0.5817 (Δ -0.0769) kept_rollouts=0 skipped_problems=4\n",
      "Step  677: train_mean_reward=0.3738 (Δ -0.2079) kept_rollouts=16 skipped_problems=3\n",
      "Step  678: train_mean_reward=0.1522 (Δ -0.2216) kept_rollouts=16 skipped_problems=3\n",
      "Step  679: train_mean_reward=0.6109 (Δ +0.4587) kept_rollouts=16 skipped_problems=3\n",
      "Step  680: train_mean_reward=0.5636 (Δ -0.0473) kept_rollouts=16 skipped_problems=3\n",
      "Step  681: train_mean_reward=0.3623 (Δ -0.2013) kept_rollouts=0 skipped_problems=4\n",
      "Step  682: train_mean_reward=0.2086 (Δ -0.1537) kept_rollouts=0 skipped_problems=4\n",
      "Step  683: train_mean_reward=0.1381 (Δ -0.0705) kept_rollouts=0 skipped_problems=4\n",
      "Step  684: train_mean_reward=0.4495 (Δ +0.3114) kept_rollouts=0 skipped_problems=4\n",
      "Step  685: train_mean_reward=0.1993 (Δ -0.2502) kept_rollouts=16 skipped_problems=3\n",
      "Step  686: train_mean_reward=0.3628 (Δ +0.1635) kept_rollouts=16 skipped_problems=3\n",
      "Step  687: train_mean_reward=0.2055 (Δ -0.1573) kept_rollouts=0 skipped_problems=4\n",
      "Step  688: train_mean_reward=0.5702 (Δ +0.3647) kept_rollouts=16 skipped_problems=3\n",
      "Step  689: train_mean_reward=0.7241 (Δ +0.1539) kept_rollouts=16 skipped_problems=3\n",
      "Step  690: train_mean_reward=0.4969 (Δ -0.2272) eval_mean_reward=0.4118 ema_eval_reward=0.3841 kept_rollouts=32 skipped_problems=2\n",
      "Step  691: train_mean_reward=0.8000 (Δ +0.3031) kept_rollouts=0 skipped_problems=4\n",
      "Step  692: train_mean_reward=0.6796 (Δ -0.1204) kept_rollouts=16 skipped_problems=3\n",
      "Step  693: train_mean_reward=0.5786 (Δ -0.1009) kept_rollouts=16 skipped_problems=3\n",
      "Step  694: train_mean_reward=0.1290 (Δ -0.4496) kept_rollouts=48 skipped_problems=1\n",
      "Step  695: train_mean_reward=0.1406 (Δ +0.0117) kept_rollouts=0 skipped_problems=4\n",
      "Step  696: train_mean_reward=0.3504 (Δ +0.2098) kept_rollouts=0 skipped_problems=4\n",
      "Step  697: train_mean_reward=0.3670 (Δ +0.0166) kept_rollouts=16 skipped_problems=3\n",
      "Step  698: train_mean_reward=0.7891 (Δ +0.4220) kept_rollouts=0 skipped_problems=4\n",
      "Step  699: train_mean_reward=0.5922 (Δ -0.1969) kept_rollouts=16 skipped_problems=3\n",
      "Step  700: train_mean_reward=0.1867 (Δ -0.4054) kept_rollouts=16 skipped_problems=3\n",
      "Step  701: train_mean_reward=0.7452 (Δ +0.5585) kept_rollouts=16 skipped_problems=3\n",
      "Step  702: train_mean_reward=0.3837 (Δ -0.3616) kept_rollouts=0 skipped_problems=4\n",
      "Step  703: train_mean_reward=0.2499 (Δ -0.1338) kept_rollouts=0 skipped_problems=4\n",
      "Step  704: train_mean_reward=0.1245 (Δ -0.1254) kept_rollouts=0 skipped_problems=4\n",
      "Step  705: train_mean_reward=0.3906 (Δ +0.2661) kept_rollouts=0 skipped_problems=4\n",
      "Step  706: train_mean_reward=0.3516 (Δ -0.0390) kept_rollouts=16 skipped_problems=3\n",
      "Step  707: train_mean_reward=0.3847 (Δ +0.0331) kept_rollouts=16 skipped_problems=3\n",
      "Step  708: train_mean_reward=0.3770 (Δ -0.0077) kept_rollouts=16 skipped_problems=3\n",
      "Step  709: train_mean_reward=0.4316 (Δ +0.0546) kept_rollouts=16 skipped_problems=3\n",
      "Step  710: train_mean_reward=0.1223 (Δ -0.3093) kept_rollouts=48 skipped_problems=1\n",
      "Step  711: train_mean_reward=0.1499 (Δ +0.0276) kept_rollouts=0 skipped_problems=4\n",
      "Step  712: train_mean_reward=0.5875 (Δ +0.4376) kept_rollouts=0 skipped_problems=4\n",
      "Step  713: train_mean_reward=0.5637 (Δ -0.0238) kept_rollouts=0 skipped_problems=4\n",
      "Step  714: train_mean_reward=0.3495 (Δ -0.2142) kept_rollouts=0 skipped_problems=4\n",
      "Step  715: train_mean_reward=0.3571 (Δ +0.0076) kept_rollouts=16 skipped_problems=3\n",
      "Step  716: train_mean_reward=0.4377 (Δ +0.0806) kept_rollouts=32 skipped_problems=2\n",
      "Step  717: train_mean_reward=0.1420 (Δ -0.2956) kept_rollouts=16 skipped_problems=3\n",
      "Step  718: train_mean_reward=0.3741 (Δ +0.2321) kept_rollouts=0 skipped_problems=4\n",
      "Step  719: train_mean_reward=0.6703 (Δ +0.2961) kept_rollouts=0 skipped_problems=4\n",
      "Step  720: train_mean_reward=0.5656 (Δ -0.1047) eval_mean_reward=0.3695 ema_eval_reward=0.3827 kept_rollouts=0 skipped_problems=4\n",
      "Step  721: train_mean_reward=1.0000 (Δ +0.4344) kept_rollouts=0 skipped_problems=4\n",
      "Step  722: train_mean_reward=0.1830 (Δ -0.8170) kept_rollouts=0 skipped_problems=4\n",
      "Step  723: train_mean_reward=0.1392 (Δ -0.0437) kept_rollouts=16 skipped_problems=3\n",
      "Step  724: train_mean_reward=0.3456 (Δ +0.2064) kept_rollouts=0 skipped_problems=4\n",
      "Step  725: train_mean_reward=0.3254 (Δ -0.0201) kept_rollouts=16 skipped_problems=3\n",
      "Step  726: train_mean_reward=0.1423 (Δ -0.1831) kept_rollouts=0 skipped_problems=4\n",
      "Step  727: train_mean_reward=0.6738 (Δ +0.5314) kept_rollouts=0 skipped_problems=4\n",
      "Step  728: train_mean_reward=0.3668 (Δ -0.3069) kept_rollouts=16 skipped_problems=3\n",
      "Step  729: train_mean_reward=0.4164 (Δ +0.0496) kept_rollouts=16 skipped_problems=3\n",
      "Step  730: train_mean_reward=0.4439 (Δ +0.0275) kept_rollouts=0 skipped_problems=4\n",
      "Step  731: train_mean_reward=0.5723 (Δ +0.1283) kept_rollouts=0 skipped_problems=4\n",
      "Step  732: train_mean_reward=0.7975 (Δ +0.2252) kept_rollouts=16 skipped_problems=3\n",
      "Step  733: train_mean_reward=0.3666 (Δ -0.4309) kept_rollouts=0 skipped_problems=4\n",
      "Step  734: train_mean_reward=0.2216 (Δ -0.1450) kept_rollouts=16 skipped_problems=3\n",
      "Step  735: train_mean_reward=0.4518 (Δ +0.2302) kept_rollouts=0 skipped_problems=4\n",
      "Step  736: train_mean_reward=0.4200 (Δ -0.0318) kept_rollouts=0 skipped_problems=4\n",
      "Step  737: train_mean_reward=0.8459 (Δ +0.4259) kept_rollouts=16 skipped_problems=3\n",
      "Step  738: train_mean_reward=0.6679 (Δ -0.1781) kept_rollouts=0 skipped_problems=4\n",
      "Step  739: train_mean_reward=0.2057 (Δ -0.4621) kept_rollouts=0 skipped_problems=4\n",
      "Step  740: train_mean_reward=0.5687 (Δ +0.3630) kept_rollouts=0 skipped_problems=4\n",
      "Step  741: train_mean_reward=0.2595 (Δ -0.3093) kept_rollouts=0 skipped_problems=4\n",
      "Step  742: train_mean_reward=0.3659 (Δ +0.1064) kept_rollouts=0 skipped_problems=4\n",
      "Step  743: train_mean_reward=0.4675 (Δ +0.1016) kept_rollouts=0 skipped_problems=4\n",
      "Step  744: train_mean_reward=0.2455 (Δ -0.2220) kept_rollouts=32 skipped_problems=2\n",
      "Step  745: train_mean_reward=0.6196 (Δ +0.3741) kept_rollouts=0 skipped_problems=4\n",
      "Step  746: train_mean_reward=0.6565 (Δ +0.0369) kept_rollouts=16 skipped_problems=3\n",
      "Step  747: train_mean_reward=0.1812 (Δ -0.4753) kept_rollouts=0 skipped_problems=4\n",
      "Step  748: train_mean_reward=0.3621 (Δ +0.1808) kept_rollouts=16 skipped_problems=3\n",
      "Step  749: train_mean_reward=0.6777 (Δ +0.3157) kept_rollouts=16 skipped_problems=3\n",
      "Step  750: train_mean_reward=0.3694 (Δ -0.3083) eval_mean_reward=0.4435 ema_eval_reward=0.3887 kept_rollouts=0 skipped_problems=4\n",
      "Step  751: train_mean_reward=0.7955 (Δ +0.4261) kept_rollouts=0 skipped_problems=4\n",
      "Step  752: train_mean_reward=0.5752 (Δ -0.2203) kept_rollouts=0 skipped_problems=4\n",
      "Step  753: train_mean_reward=0.2418 (Δ -0.3334) kept_rollouts=0 skipped_problems=4\n",
      "Step  754: train_mean_reward=0.5977 (Δ +0.3560) kept_rollouts=0 skipped_problems=4\n",
      "Step  755: train_mean_reward=0.6913 (Δ +0.0935) kept_rollouts=16 skipped_problems=3\n",
      "Step  756: train_mean_reward=0.3559 (Δ -0.3354) kept_rollouts=16 skipped_problems=3\n",
      "Step  757: train_mean_reward=0.4359 (Δ +0.0800) kept_rollouts=16 skipped_problems=3\n",
      "Step  758: train_mean_reward=0.5904 (Δ +0.1546) kept_rollouts=16 skipped_problems=3\n",
      "Step  759: train_mean_reward=0.4493 (Δ -0.1411) kept_rollouts=16 skipped_problems=3\n",
      "Step  760: train_mean_reward=0.2575 (Δ -0.1918) kept_rollouts=0 skipped_problems=4\n",
      "Step  761: train_mean_reward=0.3947 (Δ +0.1372) kept_rollouts=0 skipped_problems=4\n",
      "Step  762: train_mean_reward=0.1727 (Δ -0.2220) kept_rollouts=0 skipped_problems=4\n",
      "Step  763: train_mean_reward=0.3888 (Δ +0.2160) kept_rollouts=16 skipped_problems=3\n",
      "Step  764: train_mean_reward=0.2108 (Δ -0.1780) kept_rollouts=32 skipped_problems=2\n",
      "Step  765: train_mean_reward=0.4552 (Δ +0.2444) kept_rollouts=16 skipped_problems=3\n",
      "Step  766: train_mean_reward=0.3517 (Δ -0.1035) kept_rollouts=0 skipped_problems=4\n",
      "Step  767: train_mean_reward=0.2126 (Δ -0.1391) kept_rollouts=0 skipped_problems=4\n",
      "Step  768: train_mean_reward=0.5083 (Δ +0.2957) kept_rollouts=32 skipped_problems=2\n",
      "Step  769: train_mean_reward=0.3600 (Δ -0.1482) kept_rollouts=0 skipped_problems=4\n",
      "Step  770: train_mean_reward=0.3420 (Δ -0.0180) kept_rollouts=16 skipped_problems=3\n",
      "Step  771: train_mean_reward=0.4918 (Δ +0.1498) kept_rollouts=16 skipped_problems=3\n",
      "Step  772: train_mean_reward=0.3567 (Δ -0.1351) kept_rollouts=16 skipped_problems=3\n",
      "Step  773: train_mean_reward=0.3920 (Δ +0.0352) kept_rollouts=16 skipped_problems=3\n",
      "Step  774: train_mean_reward=0.4706 (Δ +0.0786) kept_rollouts=16 skipped_problems=3\n",
      "Step  775: train_mean_reward=0.3898 (Δ -0.0807) kept_rollouts=0 skipped_problems=4\n",
      "Step  776: train_mean_reward=0.3954 (Δ +0.0055) kept_rollouts=0 skipped_problems=4\n",
      "Step  777: train_mean_reward=0.3569 (Δ -0.0384) kept_rollouts=16 skipped_problems=3\n",
      "Step  778: train_mean_reward=0.5590 (Δ +0.2021) kept_rollouts=0 skipped_problems=4\n",
      "Step  779: train_mean_reward=0.4405 (Δ -0.1185) kept_rollouts=0 skipped_problems=4\n",
      "Step  780: train_mean_reward=0.6235 (Δ +0.1831) eval_mean_reward=0.4524 ema_eval_reward=0.3951 kept_rollouts=16 skipped_problems=3\n",
      "Step  781: train_mean_reward=0.5096 (Δ -0.1139) kept_rollouts=16 skipped_problems=3\n",
      "Step  782: train_mean_reward=0.6666 (Δ +0.1570) kept_rollouts=0 skipped_problems=4\n",
      "Step  783: train_mean_reward=0.4225 (Δ -0.2441) kept_rollouts=0 skipped_problems=4\n",
      "Step  784: train_mean_reward=0.4366 (Δ +0.0141) kept_rollouts=0 skipped_problems=4\n",
      "Step  785: train_mean_reward=0.4234 (Δ -0.0132) kept_rollouts=16 skipped_problems=3\n",
      "Step  786: train_mean_reward=0.2922 (Δ -0.1313) kept_rollouts=16 skipped_problems=3\n",
      "Step  787: train_mean_reward=0.3549 (Δ +0.0627) kept_rollouts=16 skipped_problems=3\n",
      "Step  788: train_mean_reward=0.3975 (Δ +0.0426) kept_rollouts=16 skipped_problems=3\n",
      "Step  789: train_mean_reward=0.4234 (Δ +0.0259) kept_rollouts=48 skipped_problems=1\n",
      "Step  790: train_mean_reward=0.3538 (Δ -0.0696) kept_rollouts=0 skipped_problems=4\n",
      "Step  791: train_mean_reward=0.4188 (Δ +0.0650) kept_rollouts=16 skipped_problems=3\n",
      "Step  792: train_mean_reward=0.4130 (Δ -0.0059) kept_rollouts=0 skipped_problems=4\n",
      "Step  793: train_mean_reward=0.5823 (Δ +0.1693) kept_rollouts=0 skipped_problems=4\n",
      "Step  794: train_mean_reward=0.6723 (Δ +0.0900) kept_rollouts=0 skipped_problems=4\n",
      "Step  795: train_mean_reward=0.6075 (Δ -0.0648) kept_rollouts=0 skipped_problems=4\n",
      "Step  796: train_mean_reward=0.5687 (Δ -0.0388) kept_rollouts=0 skipped_problems=4\n",
      "Step  797: train_mean_reward=0.1785 (Δ -0.3902) kept_rollouts=0 skipped_problems=4\n",
      "Step  798: train_mean_reward=0.4068 (Δ +0.2283) kept_rollouts=0 skipped_problems=4\n",
      "Step  799: train_mean_reward=0.6798 (Δ +0.2730) kept_rollouts=0 skipped_problems=4\n",
      "Step  800: train_mean_reward=0.9728 (Δ +0.2930) kept_rollouts=16 skipped_problems=3\n",
      "Step  801: train_mean_reward=0.5651 (Δ -0.4078) kept_rollouts=0 skipped_problems=4\n",
      "Step  802: train_mean_reward=0.4031 (Δ -0.1619) kept_rollouts=0 skipped_problems=4\n",
      "Step  803: train_mean_reward=0.3570 (Δ -0.0462) kept_rollouts=16 skipped_problems=3\n",
      "Step  804: train_mean_reward=0.5608 (Δ +0.2038) kept_rollouts=0 skipped_problems=4\n",
      "Step  805: train_mean_reward=0.5870 (Δ +0.0262) kept_rollouts=16 skipped_problems=3\n",
      "Step  806: train_mean_reward=0.7522 (Δ +0.1651) kept_rollouts=16 skipped_problems=3\n",
      "Step  807: train_mean_reward=0.4636 (Δ -0.2885) kept_rollouts=16 skipped_problems=3\n",
      "Step  808: train_mean_reward=0.3845 (Δ -0.0791) kept_rollouts=16 skipped_problems=3\n",
      "Step  809: train_mean_reward=0.6510 (Δ +0.2665) kept_rollouts=16 skipped_problems=3\n",
      "Step  810: train_mean_reward=0.1919 (Δ -0.4591) eval_mean_reward=0.4393 ema_eval_reward=0.3995 kept_rollouts=32 skipped_problems=2\n",
      "Step  811: train_mean_reward=0.4217 (Δ +0.2298) kept_rollouts=0 skipped_problems=4\n",
      "Step  812: train_mean_reward=0.3668 (Δ -0.0549) kept_rollouts=0 skipped_problems=4\n",
      "Step  813: train_mean_reward=0.5834 (Δ +0.2166) kept_rollouts=16 skipped_problems=3\n",
      "Step  814: train_mean_reward=0.6500 (Δ +0.0666) kept_rollouts=0 skipped_problems=4\n",
      "Step  815: train_mean_reward=0.5681 (Δ -0.0819) kept_rollouts=0 skipped_problems=4\n",
      "Step  816: train_mean_reward=0.3425 (Δ -0.2256) kept_rollouts=0 skipped_problems=4\n",
      "Step  817: train_mean_reward=0.6100 (Δ +0.2675) kept_rollouts=0 skipped_problems=4\n",
      "Step  818: train_mean_reward=0.3780 (Δ -0.2320) kept_rollouts=0 skipped_problems=4\n",
      "Step  819: train_mean_reward=0.5607 (Δ +0.1827) kept_rollouts=16 skipped_problems=3\n",
      "Step  820: train_mean_reward=0.7857 (Δ +0.2250) kept_rollouts=0 skipped_problems=4\n",
      "Step  821: train_mean_reward=0.2243 (Δ -0.5614) kept_rollouts=16 skipped_problems=3\n",
      "Step  822: train_mean_reward=0.2903 (Δ +0.0660) kept_rollouts=0 skipped_problems=4\n",
      "Step  823: train_mean_reward=0.5658 (Δ +0.2755) kept_rollouts=16 skipped_problems=3\n",
      "Step  824: train_mean_reward=0.1373 (Δ -0.4285) kept_rollouts=0 skipped_problems=4\n",
      "Step  825: train_mean_reward=0.2687 (Δ +0.1315) kept_rollouts=0 skipped_problems=4\n",
      "Step  826: train_mean_reward=0.1647 (Δ -0.1040) kept_rollouts=0 skipped_problems=4\n",
      "Step  827: train_mean_reward=0.4452 (Δ +0.2805) kept_rollouts=0 skipped_problems=4\n",
      "Step  828: train_mean_reward=0.5684 (Δ +0.1232) kept_rollouts=16 skipped_problems=3\n",
      "Step  829: train_mean_reward=0.6400 (Δ +0.0716) kept_rollouts=0 skipped_problems=4\n",
      "Step  830: train_mean_reward=0.1404 (Δ -0.4996) kept_rollouts=16 skipped_problems=3\n",
      "Step  831: train_mean_reward=0.4116 (Δ +0.2712) kept_rollouts=16 skipped_problems=3\n",
      "Step  832: train_mean_reward=0.4746 (Δ +0.0630) kept_rollouts=0 skipped_problems=4\n",
      "Step  833: train_mean_reward=0.4338 (Δ -0.0408) kept_rollouts=16 skipped_problems=3\n",
      "Step  834: train_mean_reward=0.5074 (Δ +0.0736) kept_rollouts=16 skipped_problems=3\n",
      "Step  835: train_mean_reward=0.5658 (Δ +0.0584) kept_rollouts=0 skipped_problems=4\n",
      "Step  836: train_mean_reward=0.4562 (Δ -0.1096) kept_rollouts=0 skipped_problems=4\n",
      "Step  837: train_mean_reward=0.5789 (Δ +0.1227) kept_rollouts=0 skipped_problems=4\n",
      "Step  838: train_mean_reward=0.2610 (Δ -0.3179) kept_rollouts=16 skipped_problems=3\n",
      "Step  839: train_mean_reward=0.5747 (Δ +0.3136) kept_rollouts=0 skipped_problems=4\n",
      "Step  840: train_mean_reward=0.3396 (Δ -0.2351) eval_mean_reward=0.3808 ema_eval_reward=0.3976 kept_rollouts=32 skipped_problems=2\n",
      "Step  841: train_mean_reward=0.5575 (Δ +0.2179) kept_rollouts=16 skipped_problems=3\n",
      "Step  842: train_mean_reward=0.4272 (Δ -0.1304) kept_rollouts=16 skipped_problems=3\n",
      "Step  843: train_mean_reward=0.3513 (Δ -0.0758) kept_rollouts=32 skipped_problems=2\n",
      "Step  844: train_mean_reward=0.5819 (Δ +0.2305) kept_rollouts=0 skipped_problems=4\n",
      "Step  845: train_mean_reward=0.4675 (Δ -0.1144) kept_rollouts=0 skipped_problems=4\n",
      "Step  846: train_mean_reward=0.3739 (Δ -0.0936) kept_rollouts=48 skipped_problems=1\n",
      "Step  847: train_mean_reward=0.3484 (Δ -0.0255) kept_rollouts=0 skipped_problems=4\n",
      "Step  848: train_mean_reward=0.7814 (Δ +0.4330) kept_rollouts=0 skipped_problems=4\n",
      "Step  849: train_mean_reward=0.3776 (Δ -0.4038) kept_rollouts=16 skipped_problems=3\n",
      "Step  850: train_mean_reward=0.3451 (Δ -0.0325) kept_rollouts=0 skipped_problems=4\n",
      "Step  851: train_mean_reward=0.5789 (Δ +0.2338) kept_rollouts=0 skipped_problems=4\n",
      "Step  852: train_mean_reward=0.2447 (Δ -0.3343) kept_rollouts=0 skipped_problems=4\n",
      "Step  853: train_mean_reward=0.1753 (Δ -0.0694) kept_rollouts=32 skipped_problems=2\n",
      "Step  854: train_mean_reward=0.2380 (Δ +0.0627) kept_rollouts=0 skipped_problems=4\n",
      "Step  855: train_mean_reward=0.1850 (Δ -0.0530) kept_rollouts=16 skipped_problems=3\n",
      "Step  856: train_mean_reward=0.1882 (Δ +0.0032) kept_rollouts=16 skipped_problems=3\n",
      "Step  857: train_mean_reward=0.8313 (Δ +0.6431) kept_rollouts=0 skipped_problems=4\n",
      "Step  858: train_mean_reward=0.2273 (Δ -0.6039) kept_rollouts=0 skipped_problems=4\n",
      "Step  859: train_mean_reward=0.2422 (Δ +0.0148) kept_rollouts=16 skipped_problems=3\n",
      "Step  860: train_mean_reward=0.4108 (Δ +0.1686) kept_rollouts=32 skipped_problems=2\n",
      "Step  861: train_mean_reward=0.2368 (Δ -0.1740) kept_rollouts=0 skipped_problems=4\n",
      "Step  862: train_mean_reward=0.4003 (Δ +0.1635) kept_rollouts=0 skipped_problems=4\n",
      "Step  863: train_mean_reward=0.3467 (Δ -0.0536) kept_rollouts=0 skipped_problems=4\n",
      "Step  864: train_mean_reward=0.5181 (Δ +0.1714) kept_rollouts=48 skipped_problems=1\n",
      "Step  865: train_mean_reward=0.3722 (Δ -0.1458) kept_rollouts=0 skipped_problems=4\n",
      "Step  866: train_mean_reward=0.2262 (Δ -0.1460) kept_rollouts=0 skipped_problems=4\n",
      "Step  867: train_mean_reward=0.7800 (Δ +0.5538) kept_rollouts=0 skipped_problems=4\n",
      "Step  868: train_mean_reward=0.4522 (Δ -0.3278) kept_rollouts=32 skipped_problems=2\n",
      "Step  869: train_mean_reward=0.6575 (Δ +0.2053) kept_rollouts=16 skipped_problems=3\n",
      "Step  870: train_mean_reward=0.3402 (Δ -0.3173) eval_mean_reward=0.4560 ema_eval_reward=0.4035 kept_rollouts=0 skipped_problems=4\n",
      "Step  871: train_mean_reward=0.4004 (Δ +0.0602) kept_rollouts=0 skipped_problems=4\n",
      "Step  872: train_mean_reward=0.3574 (Δ -0.0430) kept_rollouts=16 skipped_problems=3\n",
      "Step  873: train_mean_reward=0.3569 (Δ -0.0005) kept_rollouts=32 skipped_problems=2\n",
      "Step  874: train_mean_reward=0.5802 (Δ +0.2234) kept_rollouts=0 skipped_problems=4\n",
      "Step  875: train_mean_reward=0.6672 (Δ +0.0869) kept_rollouts=16 skipped_problems=3\n",
      "Step  876: train_mean_reward=0.4525 (Δ -0.2147) kept_rollouts=0 skipped_problems=4\n",
      "Step  877: train_mean_reward=0.7785 (Δ +0.3261) kept_rollouts=16 skipped_problems=3\n",
      "Step  878: train_mean_reward=0.2078 (Δ -0.5707) kept_rollouts=32 skipped_problems=2\n",
      "Step  879: train_mean_reward=0.2481 (Δ +0.0403) kept_rollouts=16 skipped_problems=3\n",
      "Step  880: train_mean_reward=0.3630 (Δ +0.1149) kept_rollouts=32 skipped_problems=2\n",
      "Step  881: train_mean_reward=0.2897 (Δ -0.0733) kept_rollouts=16 skipped_problems=3\n",
      "Step  882: train_mean_reward=0.2424 (Δ -0.0473) kept_rollouts=0 skipped_problems=4\n",
      "Step  883: train_mean_reward=0.4483 (Δ +0.2060) kept_rollouts=16 skipped_problems=3\n",
      "Step  884: train_mean_reward=0.5573 (Δ +0.1089) kept_rollouts=16 skipped_problems=3\n",
      "Step  885: train_mean_reward=0.2955 (Δ -0.2618) kept_rollouts=16 skipped_problems=3\n",
      "Step  886: train_mean_reward=0.1391 (Δ -0.1564) kept_rollouts=0 skipped_problems=4\n",
      "Step  887: train_mean_reward=0.3894 (Δ +0.2503) kept_rollouts=16 skipped_problems=3\n",
      "Step  888: train_mean_reward=0.3814 (Δ -0.0080) kept_rollouts=16 skipped_problems=3\n",
      "Step  889: train_mean_reward=0.3549 (Δ -0.0265) kept_rollouts=0 skipped_problems=4\n",
      "Step  890: train_mean_reward=0.3542 (Δ -0.0006) kept_rollouts=0 skipped_problems=4\n",
      "Step  891: train_mean_reward=0.4037 (Δ +0.0494) kept_rollouts=16 skipped_problems=3\n",
      "Step  892: train_mean_reward=0.4983 (Δ +0.0946) kept_rollouts=16 skipped_problems=3\n",
      "Step  893: train_mean_reward=0.5716 (Δ +0.0733) kept_rollouts=0 skipped_problems=4\n",
      "Step  894: train_mean_reward=0.1318 (Δ -0.4397) kept_rollouts=0 skipped_problems=4\n",
      "Step  895: train_mean_reward=0.5013 (Δ +0.3695) kept_rollouts=16 skipped_problems=3\n",
      "Step  896: train_mean_reward=0.8000 (Δ +0.2987) kept_rollouts=0 skipped_problems=4\n",
      "Step  897: train_mean_reward=0.3521 (Δ -0.4479) kept_rollouts=0 skipped_problems=4\n",
      "Step  898: train_mean_reward=0.2525 (Δ -0.0995) kept_rollouts=0 skipped_problems=4\n",
      "Step  899: train_mean_reward=0.3113 (Δ +0.0587) kept_rollouts=16 skipped_problems=3\n",
      "Step  900: train_mean_reward=0.1481 (Δ -0.1631) eval_mean_reward=0.4849 ema_eval_reward=0.4116 kept_rollouts=0 skipped_problems=4\n",
      "Step  901: train_mean_reward=0.2291 (Δ +0.0810) kept_rollouts=32 skipped_problems=2\n",
      "Step  902: train_mean_reward=0.3963 (Δ +0.1673) kept_rollouts=0 skipped_problems=4\n",
      "Step  903: train_mean_reward=0.5465 (Δ +0.1502) kept_rollouts=32 skipped_problems=2\n",
      "Step  904: train_mean_reward=0.6686 (Δ +0.1221) kept_rollouts=0 skipped_problems=4\n",
      "Step  905: train_mean_reward=0.5722 (Δ -0.0963) kept_rollouts=0 skipped_problems=4\n",
      "Step  906: train_mean_reward=0.7375 (Δ +0.1653) kept_rollouts=16 skipped_problems=3\n",
      "Step  907: train_mean_reward=0.4571 (Δ -0.2804) kept_rollouts=16 skipped_problems=3\n",
      "Step  908: train_mean_reward=0.2221 (Δ -0.2350) kept_rollouts=32 skipped_problems=2\n",
      "Step  909: train_mean_reward=0.1424 (Δ -0.0798) kept_rollouts=0 skipped_problems=4\n",
      "Step  910: train_mean_reward=0.1817 (Δ +0.0393) kept_rollouts=0 skipped_problems=4\n",
      "Step  911: train_mean_reward=0.4750 (Δ +0.2933) kept_rollouts=0 skipped_problems=4\n",
      "Step  912: train_mean_reward=0.4923 (Δ +0.0173) kept_rollouts=0 skipped_problems=4\n",
      "Step  913: train_mean_reward=0.5809 (Δ +0.0886) kept_rollouts=0 skipped_problems=4\n",
      "Step  914: train_mean_reward=0.3762 (Δ -0.2048) kept_rollouts=0 skipped_problems=4\n",
      "Step  915: train_mean_reward=0.5986 (Δ +0.2225) kept_rollouts=16 skipped_problems=3\n",
      "Step  916: train_mean_reward=0.1988 (Δ -0.3999) kept_rollouts=16 skipped_problems=3\n",
      "Step  917: train_mean_reward=0.6520 (Δ +0.4532) kept_rollouts=32 skipped_problems=2\n",
      "Step  918: train_mean_reward=0.2482 (Δ -0.4038) kept_rollouts=32 skipped_problems=2\n",
      "Step  919: train_mean_reward=0.2304 (Δ -0.0178) kept_rollouts=16 skipped_problems=3\n",
      "Step  920: train_mean_reward=0.2339 (Δ +0.0035) kept_rollouts=16 skipped_problems=3\n",
      "Step  921: train_mean_reward=0.5752 (Δ +0.3413) kept_rollouts=16 skipped_problems=3\n",
      "Step  922: train_mean_reward=0.6378 (Δ +0.0626) kept_rollouts=16 skipped_problems=3\n",
      "Step  923: train_mean_reward=0.3738 (Δ -0.2640) kept_rollouts=32 skipped_problems=2\n",
      "Step  924: train_mean_reward=0.5625 (Δ +0.1887) kept_rollouts=0 skipped_problems=4\n",
      "Step  925: train_mean_reward=0.1947 (Δ -0.3678) kept_rollouts=16 skipped_problems=3\n",
      "Step  926: train_mean_reward=0.4600 (Δ +0.2653) kept_rollouts=0 skipped_problems=4\n",
      "Step  927: train_mean_reward=0.6396 (Δ +0.1796) kept_rollouts=32 skipped_problems=2\n",
      "Step  928: train_mean_reward=0.5648 (Δ -0.0748) kept_rollouts=16 skipped_problems=3\n",
      "Step  929: train_mean_reward=0.3748 (Δ -0.1900) kept_rollouts=0 skipped_problems=4\n",
      "Step  930: train_mean_reward=0.7777 (Δ +0.4029) eval_mean_reward=0.4113 ema_eval_reward=0.4116 kept_rollouts=0 skipped_problems=4\n",
      "Step  931: train_mean_reward=0.4570 (Δ -0.3207) kept_rollouts=0 skipped_problems=4\n",
      "Step  932: train_mean_reward=0.3890 (Δ -0.0680) kept_rollouts=0 skipped_problems=4\n",
      "Step  933: train_mean_reward=0.1570 (Δ -0.2320) kept_rollouts=16 skipped_problems=3\n",
      "Step  934: train_mean_reward=0.2653 (Δ +0.1082) kept_rollouts=0 skipped_problems=4\n",
      "Step  935: train_mean_reward=0.1380 (Δ -0.1273) kept_rollouts=16 skipped_problems=3\n",
      "Step  936: train_mean_reward=0.3683 (Δ +0.2303) kept_rollouts=32 skipped_problems=2\n",
      "Step  937: train_mean_reward=0.6946 (Δ +0.3264) kept_rollouts=0 skipped_problems=4\n",
      "Step  938: train_mean_reward=0.6611 (Δ -0.0336) kept_rollouts=16 skipped_problems=3\n",
      "Step  939: train_mean_reward=0.1659 (Δ -0.4952) kept_rollouts=0 skipped_problems=4\n",
      "Step  940: train_mean_reward=0.2125 (Δ +0.0466) kept_rollouts=0 skipped_problems=4\n",
      "Step  941: train_mean_reward=0.1543 (Δ -0.0582) kept_rollouts=16 skipped_problems=3\n",
      "Step  942: train_mean_reward=0.4781 (Δ +0.3239) kept_rollouts=0 skipped_problems=4\n",
      "Step  943: train_mean_reward=0.4100 (Δ -0.0682) kept_rollouts=0 skipped_problems=4\n",
      "Step  944: train_mean_reward=0.1358 (Δ -0.2742) kept_rollouts=16 skipped_problems=3\n",
      "Step  945: train_mean_reward=0.6766 (Δ +0.5408) kept_rollouts=0 skipped_problems=4\n",
      "Step  946: train_mean_reward=0.3737 (Δ -0.3028) kept_rollouts=16 skipped_problems=3\n",
      "Step  947: train_mean_reward=0.5571 (Δ +0.1834) kept_rollouts=32 skipped_problems=2\n",
      "Step  948: train_mean_reward=0.6766 (Δ +0.1195) kept_rollouts=0 skipped_problems=4\n",
      "Step  949: train_mean_reward=0.3616 (Δ -0.3150) kept_rollouts=0 skipped_problems=4\n",
      "Step  950: train_mean_reward=0.6695 (Δ +0.3079) kept_rollouts=16 skipped_problems=3\n",
      "Step  951: train_mean_reward=0.3539 (Δ -0.3155) kept_rollouts=16 skipped_problems=3\n",
      "Step  952: train_mean_reward=0.5840 (Δ +0.2301) kept_rollouts=0 skipped_problems=4\n",
      "Step  953: train_mean_reward=0.5946 (Δ +0.0106) kept_rollouts=0 skipped_problems=4\n",
      "Step  954: train_mean_reward=0.6301 (Δ +0.0355) kept_rollouts=16 skipped_problems=3\n",
      "Step  955: train_mean_reward=0.4992 (Δ -0.1310) kept_rollouts=16 skipped_problems=3\n",
      "Step  956: train_mean_reward=0.3705 (Δ -0.1287) kept_rollouts=0 skipped_problems=4\n",
      "Step  957: train_mean_reward=0.3445 (Δ -0.0259) kept_rollouts=0 skipped_problems=4\n",
      "Step  958: train_mean_reward=0.5642 (Δ +0.2196) kept_rollouts=0 skipped_problems=4\n",
      "Step  959: train_mean_reward=0.1761 (Δ -0.3881) kept_rollouts=32 skipped_problems=2\n",
      "Step  960: train_mean_reward=0.3647 (Δ +0.1886) eval_mean_reward=0.4507 ema_eval_reward=0.4155 kept_rollouts=0 skipped_problems=4\n",
      "Step  961: train_mean_reward=0.8875 (Δ +0.5228) kept_rollouts=0 skipped_problems=4\n",
      "Step  962: train_mean_reward=0.1643 (Δ -0.7232) kept_rollouts=0 skipped_problems=4\n",
      "Step  963: train_mean_reward=0.4912 (Δ +0.3269) kept_rollouts=32 skipped_problems=2\n",
      "Step  964: train_mean_reward=0.7794 (Δ +0.2883) kept_rollouts=0 skipped_problems=4\n",
      "Step  965: train_mean_reward=0.6326 (Δ -0.1468) kept_rollouts=48 skipped_problems=1\n",
      "Step  966: train_mean_reward=0.4195 (Δ -0.2132) kept_rollouts=0 skipped_problems=4\n",
      "Step  967: train_mean_reward=0.4946 (Δ +0.0752) kept_rollouts=0 skipped_problems=4\n",
      "Step  968: train_mean_reward=0.3785 (Δ -0.1161) kept_rollouts=32 skipped_problems=2\n",
      "Step  969: train_mean_reward=0.1394 (Δ -0.2392) kept_rollouts=16 skipped_problems=3\n",
      "Step  970: train_mean_reward=0.5776 (Δ +0.4382) kept_rollouts=16 skipped_problems=3\n",
      "Step  971: train_mean_reward=0.3307 (Δ -0.2468) kept_rollouts=32 skipped_problems=2\n",
      "Step  972: train_mean_reward=0.3412 (Δ +0.0104) kept_rollouts=32 skipped_problems=2\n",
      "Step  973: train_mean_reward=0.2002 (Δ -0.1410) kept_rollouts=32 skipped_problems=2\n",
      "Step  974: train_mean_reward=0.6200 (Δ +0.4198) kept_rollouts=0 skipped_problems=4\n",
      "Step  975: train_mean_reward=0.7427 (Δ +0.1227) kept_rollouts=16 skipped_problems=3\n",
      "Step  976: train_mean_reward=0.3565 (Δ -0.3861) kept_rollouts=16 skipped_problems=3\n",
      "Step  977: train_mean_reward=0.3990 (Δ +0.0425) kept_rollouts=32 skipped_problems=2\n",
      "Step  978: train_mean_reward=0.1392 (Δ -0.2598) kept_rollouts=48 skipped_problems=1\n",
      "Step  979: train_mean_reward=0.3685 (Δ +0.2293) kept_rollouts=16 skipped_problems=3\n",
      "Step  980: train_mean_reward=0.4186 (Δ +0.0501) kept_rollouts=16 skipped_problems=3\n",
      "Step  981: train_mean_reward=0.2702 (Δ -0.1484) kept_rollouts=16 skipped_problems=3\n",
      "Step  982: train_mean_reward=0.3544 (Δ +0.0842) kept_rollouts=0 skipped_problems=4\n",
      "Step  983: train_mean_reward=0.1604 (Δ -0.1940) kept_rollouts=16 skipped_problems=3\n",
      "Step  984: train_mean_reward=0.2473 (Δ +0.0868) kept_rollouts=16 skipped_problems=3\n",
      "Step  985: train_mean_reward=0.4265 (Δ +0.1792) kept_rollouts=32 skipped_problems=2\n",
      "Step  986: train_mean_reward=0.2229 (Δ -0.2036) kept_rollouts=16 skipped_problems=3\n",
      "Step  987: train_mean_reward=0.5445 (Δ +0.3216) kept_rollouts=32 skipped_problems=2\n",
      "Step  988: train_mean_reward=0.5682 (Δ +0.0237) kept_rollouts=16 skipped_problems=3\n",
      "Step  989: train_mean_reward=0.2559 (Δ -0.3123) kept_rollouts=0 skipped_problems=4\n",
      "Step  990: train_mean_reward=0.4212 (Δ +0.1653) eval_mean_reward=0.4994 ema_eval_reward=0.4239 kept_rollouts=16 skipped_problems=3\n",
      "Step  991: train_mean_reward=0.5670 (Δ +0.1458) kept_rollouts=0 skipped_problems=4\n",
      "Step  992: train_mean_reward=0.5853 (Δ +0.0183) kept_rollouts=16 skipped_problems=3\n",
      "Step  993: train_mean_reward=0.1403 (Δ -0.4450) kept_rollouts=32 skipped_problems=2\n",
      "Step  994: train_mean_reward=0.7882 (Δ +0.6479) kept_rollouts=16 skipped_problems=3\n",
      "Step  995: train_mean_reward=0.1500 (Δ -0.6382) kept_rollouts=16 skipped_problems=3\n",
      "Step  996: train_mean_reward=0.1201 (Δ -0.0299) kept_rollouts=0 skipped_problems=4\n",
      "Step  997: train_mean_reward=0.3596 (Δ +0.2395) kept_rollouts=0 skipped_problems=4\n",
      "Step  998: train_mean_reward=0.3926 (Δ +0.0330) kept_rollouts=0 skipped_problems=4\n",
      "Step  999: train_mean_reward=0.4580 (Δ +0.0654) kept_rollouts=0 skipped_problems=4\n",
      "\n",
      "Training complete!\n",
      "Initial train_mean_reward: 0.1376\n",
      "Final train_mean_reward:   0.4580\n"
     ]
    }
   ],
   "source": [
    "ema_eval_reward = None\n",
    "metrics_history = []\n",
    "\n",
    "print(f\"Starting RL training: {NUM_STEPS} steps\")\n",
    "print(f\"Batch: {BATCH_SIZE}, Group: {GROUP_SIZE}, LR: {LEARNING_RATE}\\n\")\n",
    "\n",
    "for step in range(NUM_STEPS):\n",
    "    problems_P = dataset.get_batch(BATCH_SIZE, split=\"train\")\n",
    "\n",
    "    # Sync weights -> sampling client\n",
    "    save_result = training_client.save_weights_for_sampler(name=f\"rl_step_{step:06d}\").result()\n",
    "    sampling_path = save_result.path\n",
    "    sampling_client = service_client.create_sampling_client(model_path=sampling_path)\n",
    "\n",
    "    datums_D: list[types.Datum] = []\n",
    "    mean_rewards_P: list[float] = []\n",
    "    kept_rollouts = 0\n",
    "    skipped_problems = 0\n",
    "\n",
    "    # Sample + build datums\n",
    "    for prob in problems_P:\n",
    "        prompt_text = COUNTDOWN_FEWSHOT + prob.question\n",
    "        prompt = make_prompt_model_input(prompt_text)\n",
    "\n",
    "        sample_res = sampling_client.sample(\n",
    "            prompt=prompt,\n",
    "            num_samples=GROUP_SIZE,\n",
    "            sampling_params=sampling_params_train,\n",
    "        ).result()\n",
    "\n",
    "        rewards_G: list[float] = []\n",
    "        tokens_G_T: list[list[int]] = []\n",
    "        logprobs_G_T: list[list[float]] = []\n",
    "\n",
    "        for seq in sample_res.sequences:\n",
    "            toks = list(seq.tokens)\n",
    "            lps = seq.logprobs\n",
    "            if lps is None:\n",
    "                raise RuntimeError(\"Sampling did not return logprobs.\")\n",
    "\n",
    "            resp_text = tokenizer.decode(toks, skip_special_tokens=True)\n",
    "            r = compute_reward(\n",
    "                response_text=resp_text,\n",
    "                target=prob.target,\n",
    "                nums=prob.nums,\n",
    "                format_score=FORMAT_SCORE,\n",
    "                use_continuous_shaping=USE_CONTINUOUS_SHAPING,\n",
    "            )\n",
    "\n",
    "            rewards_G.append(float(r))\n",
    "            tokens_G_T.append(toks)\n",
    "            logprobs_G_T.append(list(lps))\n",
    "\n",
    "        mean_r = sum(rewards_G) / len(rewards_G)\n",
    "        mean_rewards_P.append(mean_r)\n",
    "\n",
    "        var_r = sum((r - mean_r) ** 2 for r in rewards_G) / max(1, len(rewards_G))\n",
    "        std_r = var_r**0.5\n",
    "        if std_r < 1e-8:\n",
    "            skipped_problems += 1\n",
    "            continue\n",
    "\n",
    "        advantages_G = [(r - mean_r) / (std_r + 1e-6) for r in rewards_G]\n",
    "\n",
    "        ob_len = prompt.length - 1\n",
    "\n",
    "        for toks, lps, adv in zip(tokens_G_T, logprobs_G_T, advantages_G, strict=True):\n",
    "            # model_input excludes final token because training usually predicts next token\n",
    "            model_input = prompt.append(types.EncodedTextChunk(tokens=toks[:-1]))\n",
    "\n",
    "            # Align lengths with model_input.length\n",
    "            target_tokens = [0] * ob_len + toks\n",
    "            padded_sampling_logprobs = [0.0] * ob_len + lps\n",
    "            padded_advantages = [0.0] * ob_len + [adv] * (model_input.length - ob_len)\n",
    "\n",
    "            assert (\n",
    "                model_input.length\n",
    "                == len(target_tokens)\n",
    "                == len(padded_sampling_logprobs)\n",
    "                == len(padded_advantages)\n",
    "            ), (\n",
    "                model_input.length,\n",
    "                len(target_tokens),\n",
    "                len(padded_sampling_logprobs),\n",
    "                len(padded_advantages),\n",
    "            )\n",
    "\n",
    "            target_tokens_t = torch.tensor(target_tokens, dtype=torch.long)\n",
    "            logprobs_t = torch.tensor(padded_sampling_logprobs, dtype=torch.float32)\n",
    "            advantages_t = torch.tensor(padded_advantages, dtype=torch.float32)\n",
    "\n",
    "            loss_fn_inputs = {\n",
    "                \"target_tokens\": TensorData.from_torch(target_tokens_t),\n",
    "                \"logprobs\": TensorData.from_torch(logprobs_t),\n",
    "                \"advantages\": TensorData.from_torch(advantages_t),\n",
    "            }\n",
    "\n",
    "            datums_D.append(\n",
    "                types.Datum(\n",
    "                    model_input=model_input,\n",
    "                    loss_fn_inputs=loss_fn_inputs,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            kept_rollouts += 1\n",
    "\n",
    "    mean_reward_train = sum(mean_rewards_P) / max(1, len(mean_rewards_P))\n",
    "\n",
    "    # Optimization step\n",
    "    if datums_D:\n",
    "        _ = training_client.forward_backward(datums_D, loss_fn=\"importance_sampling\").result()\n",
    "        _ = training_client.optim_step(adam_params).result()\n",
    "\n",
    "    # Eval + EMA\n",
    "    eval_reward = None\n",
    "    ema_now = None\n",
    "    if EVAL_EVERY > 0 and (step % EVAL_EVERY == 0):\n",
    "        eval_reward = do_eval(step)\n",
    "        if ema_eval_reward is None:\n",
    "            ema_eval_reward = eval_reward\n",
    "        else:\n",
    "            a = REWARD_EMA_ALPHA\n",
    "            ema_eval_reward = (1 - a) * ema_eval_reward + a * eval_reward\n",
    "        ema_now = ema_eval_reward\n",
    "\n",
    "    metrics_history.append(\n",
    "        {\n",
    "            \"step\": int(step),\n",
    "            \"train_mean_reward\": float(mean_reward_train),\n",
    "            \"eval_mean_reward\": None if eval_reward is None else float(eval_reward),\n",
    "            \"ema_eval_reward\": None if ema_now is None else float(ema_now),\n",
    "            \"kept_rollouts\": int(kept_rollouts),\n",
    "            \"skipped_problems\": int(skipped_problems),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if step == 0:\n",
    "        delta_train = 0.0\n",
    "    else:\n",
    "        prev = metrics_history[-2][\"train_mean_reward\"]\n",
    "        delta_train = mean_reward_train - prev\n",
    "\n",
    "    if eval_reward is None:\n",
    "        print(\n",
    "            f\"Step {step:4d}: train_mean_reward={mean_reward_train:.4f} (Δ {delta_train:+.4f}) \"\n",
    "            f\"kept_rollouts={kept_rollouts} skipped_problems={skipped_problems}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"Step {step:4d}: train_mean_reward={mean_reward_train:.4f} (Δ {delta_train:+.4f}) \"\n",
    "            f\"eval_mean_reward={eval_reward:.4f} ema_eval_reward={ema_now:.4f} \"\n",
    "            f\"kept_rollouts={kept_rollouts} skipped_problems={skipped_problems}\"\n",
    "        )\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "if metrics_history:\n",
    "    print(\"Initial train_mean_reward:\", f\"{metrics_history[0]['train_mean_reward']:.4f}\")\n",
    "    print(\"Final train_mean_reward:  \", f\"{metrics_history[-1]['train_mean_reward']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8f67d",
   "metadata": {},
   "source": [
    "## 9) Final evaluation + plotting + checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6d5e58",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-01-27T12:11:48.409959Z",
     "iopub.status.busy": "2026-01-27T12:11:48.409730Z",
     "iopub.status.idle": "2026-01-27T12:11:51.756368Z",
     "shell.execute_reply": "2026-01-27T12:11:51.755834Z",
     "shell.execute_reply.started": "2026-01-27T12:11:48.409943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation:\n",
      "============================================================\n",
      "[0] Q: Using the numbers 66, 4, 31, reach the target number 31. You may use +, -, *, / and parentheses, ...\n",
      "A: <answer>(66 - 4) - 31</answer>... [PASS] reward=1.0000\n",
      "\n",
      "Plot points (eval): 34\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: tinker://ffe4ca7d-b664-4a85-9f0b-bfc931287c98/weights/COUNTDOWN-rl-final\n"
     ]
    }
   ],
   "source": [
    "final_path = training_client.save_weights_for_sampler(name=\"COUNTDOWN-final\").result().path\n",
    "final_client = service_client.create_sampling_client(model_path=final_path)\n",
    "\n",
    "test_problems = dataset.get_batch(1, split=\"test\")\n",
    "\n",
    "print(\"Final Evaluation:\")\n",
    "print(\"=\" * 60)\n",
    "correct = 0\n",
    "\n",
    "# Some backends dislike temperature=0.0; keep a safe fallback.\n",
    "greedy_temp = 0.0\n",
    "\n",
    "for i, problem in enumerate(test_problems):\n",
    "    prompt_text = COUNTDOWN_FEWSHOT + problem.question\n",
    "    prompt_input = make_prompt_model_input(prompt_text)\n",
    "\n",
    "    try:\n",
    "        sampling_params_greedy = types.SamplingParams(\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=greedy_temp,\n",
    "            stop=STOP_SEQS,\n",
    "        )\n",
    "        result = final_client.sample(\n",
    "            prompt=prompt_input,\n",
    "            num_samples=1,\n",
    "            sampling_params=sampling_params_greedy,\n",
    "        ).result()\n",
    "    except Exception as e:\n",
    "        print(\"Greedy temp=0.0 failed, retrying with temp=0.1. Error:\", repr(e))\n",
    "        sampling_params_greedy = types.SamplingParams(\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=0.1,\n",
    "            stop=STOP_SEQS,\n",
    "        )\n",
    "        result = final_client.sample(\n",
    "            prompt=prompt_input,\n",
    "            num_samples=1,\n",
    "            sampling_params=sampling_params_greedy,\n",
    "        ).result()\n",
    "\n",
    "    response = tokenizer.decode(result.sequences[0].tokens, skip_special_tokens=True)\n",
    "    reward = compute_reward(\n",
    "        response_text=response,\n",
    "        target=problem.target,\n",
    "        nums=problem.nums,\n",
    "        format_score=FORMAT_SCORE,\n",
    "        use_continuous_shaping=USE_CONTINUOUS_SHAPING,\n",
    "    )\n",
    "\n",
    "    if reward >= 1.0:\n",
    "        correct += 1\n",
    "\n",
    "    status = \"PASS\" if reward >= 1.0 else \"FAIL\"\n",
    "    print(f\"[{i}] {problem.question[:100]}...\")\n",
    "    print(f\"A: {response.strip()[:140]}... [{status}] reward={reward:.4f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Plot eval mean reward (EMA optional)\n",
    "eval_ms = [m for m in metrics_history if m.get(\"eval_mean_reward\") is not None]\n",
    "eval_steps = [m[\"step\"] for m in eval_ms]\n",
    "eval_rewards = [m[\"eval_mean_reward\"] for m in eval_ms]\n",
    "\n",
    "ema_ms = [m for m in metrics_history if m.get(\"ema_eval_reward\") is not None]\n",
    "ema_steps = [m[\"step\"] for m in ema_ms]\n",
    "ema_rewards = [m[\"ema_eval_reward\"] for m in ema_ms]\n",
    "\n",
    "print(\"Plot points (eval):\", len(eval_steps))\n",
    "if len(eval_steps) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(eval_steps, eval_rewards, \"b-\", linewidth=2, label=\"eval_mean_reward\")\n",
    "    if len(ema_steps) > 0:\n",
    "        plt.plot(ema_steps, ema_rewards, \"r-\", linewidth=2, alpha=0.9, label=\"ema_eval_reward\")\n",
    "\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Eval mean reward\")\n",
    "    plt.title(\"COUNTDOWN RL Training\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_path = \"COUNTDOWN_training.png\"\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No eval points available to plot. (Did you set EVAL_EVERY > 0?)\")\n",
    "\n",
    "\n",
    "checkpoint = training_client.save_state(name=\"COUNTDOWN-rl-final\").result()\n",
    "print(\"Checkpoint:\", checkpoint.path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
